{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back_propagation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefcian/Modern-Computer-Vision-with-PyTorch-2E/blob/main/Chapter01/Back_propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:49.845714Z",
          "start_time": "2020-09-24T13:36:49.666592Z"
        },
        "id": "TTWK_bQBC7mf"
      },
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "x = np.array([[1,1]])\n",
        "y = np.array([[0]])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:49.850377Z",
          "start_time": "2020-09-24T13:36:49.846832Z"
        },
        "id": "V8f13jAKC9Rv"
      },
      "source": [
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "def feed_forward(inputs, outputs, weights):\n",
        "    pre_hidden = np.dot(inputs,weights[0])+ weights[1]\n",
        "    print(\"\\nhidden before activation = \" + str(pre_hidden))\n",
        "    hidden = 1/(1+np.exp(-pre_hidden))\n",
        "    print(\"hidden after activation = \" + str(hidden))\n",
        "    out = np.dot(hidden, weights[2]) + weights[3]\n",
        "    print(\"out value = \" + str(out))\n",
        "    mean_squared_error = np.mean(np.square(out - outputs))\n",
        "    return mean_squared_error"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:49.855575Z",
          "start_time": "2020-09-24T13:36:49.851797Z"
        },
        "id": "8mF3nQbMC_Ja"
      },
      "source": [
        "def update_weights(inputs, outputs, weights, lr):\n",
        "    original_weights = deepcopy(weights)\n",
        "    temp_weights = deepcopy(weights)\n",
        "    updated_weights = deepcopy(weights)\n",
        "    original_loss = feed_forward(inputs, outputs, original_weights)\n",
        "    print(\"loss_original = \" + str(original_loss))\n",
        "    for i, layer in enumerate(original_weights):\n",
        "        for index, weight in np.ndenumerate(layer):\n",
        "            temp_weights = deepcopy(weights)\n",
        "            print(\"\\ntemp_weights[\" + str(i) + \"][\" + str(index) + \"] = \" + str(temp_weights[i][index]) + \" before +0.0001 perturbation\")\n",
        "            temp_weights[i][index] += 0.0001\n",
        "            print(\"temp_weights[\" + str(i) + \"][\" + str(index) + \"] = \" + str(temp_weights[i][index]) + \" after +0.0001 perturbation\")\n",
        "            _loss_plus = feed_forward(inputs, outputs, temp_weights)\n",
        "            grad = (_loss_plus - original_loss)/(0.0001)\n",
        "            updated_weights[i][index] -= grad*lr\n",
        "            print(\"loss_plus = \" + str(_loss_plus))\n",
        "            print(\"grad = \" + str(grad))\n",
        "            print(\"lr = \" + str(lr))\n",
        "            print(\"updated_weights[\" + str(i) + \"][\" + str(index) + \"] = \" + str(updated_weights[i][index]))\n",
        "    return updated_weights, original_loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:49.859883Z",
          "start_time": "2020-09-24T13:36:49.856643Z"
        },
        "id": "jgka7ZyOC_Ow",
        "scrolled": false
      },
      "source": [
        "W = [\n",
        "    np.array([[0.8, 0.2],\n",
        "              [0.4, 0.9],\n",
        "              [0.3, 0.5]], dtype=np.float32).T,\n",
        "    np.array([-0.1, 0.5, -0.6], dtype=np.float32),\n",
        "    np.array([[ 0.3, 0.5, 0.9]], dtype=np.float32).T,\n",
        "    np.array([-0.5], dtype=np.float32)\n",
        "]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:50.261156Z",
          "start_time": "2020-09-24T13:36:49.860952Z"
        },
        "id": "EFr7P1F0C_L_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23577ebb-4fc7-4699-d446-ce9ff5f4384e",
        "collapsed": true
      },
      "source": [
        "losses = []\n",
        "for epoch in range(1000):\n",
        "    W, loss = update_weights(x,y,W,0.01)\n",
        "    losses.append(loss)\n",
        "plt.plot(losses)\n",
        "plt.title('Loss over increasing number of epochs')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "hidden after activation = [[0.70426837 0.85378644 0.51265211]]\n",
            "out value = [[-2.08709415e-05]]\n",
            "loss_plus = 4.355961976063027e-10\n",
            "grad = -1.1784997853778641e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017828\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923813 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933813 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780713 1.76461276 0.05051926]]\n",
            "hidden after activation = [[0.7042892  0.85378644 0.51262713]]\n",
            "out value = [[-3.74566395e-05]]\n",
            "loss_plus = 1.4029998445333883e-09\n",
            "grad = -2.110961384507786e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923815\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76471278 0.05051926]]\n",
            "hidden after activation = [[0.70426837 0.85379892 0.51262713]]\n",
            "out value = [[-3.64944132e-05]]\n",
            "loss_plus = 1.3318421944456574e-09\n",
            "grad = -2.8225378853850944e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017728 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027727 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76461276 0.05061924]]\n",
            "hidden after activation = [[0.70426837 0.85378644 0.51265211]]\n",
            "out value = [[-2.08709415e-05]]\n",
            "loss_plus = 4.355961976063027e-10\n",
            "grad = -1.1784997853778641e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501774\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110756285 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110656284 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780713 1.76461276 0.05051926]]\n",
            "hidden after activation = [[0.7042892  0.85378644 0.51262713]]\n",
            "out value = [[-3.74566395e-05]]\n",
            "loss_plus = 1.4029998445333883e-09\n",
            "grad = -2.110961384507786e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075626\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821294 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831293 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76471275 0.05051926]]\n",
            "hidden after activation = [[0.70426837 0.85379892 0.51262713]]\n",
            "out value = [[-3.64955101e-05]]\n",
            "loss_plus = 1.3319222586900435e-09\n",
            "grad = -2.8217372429412334e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821297\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498362 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973617 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76461276 0.05061927]]\n",
            "hidden after activation = [[0.70426837 0.85378644 0.51265212]]\n",
            "out value = [[-2.08651874e-05]]\n",
            "loss_plus = 4.353560457128765e-10\n",
            "grad = -1.1787399372712903e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983606\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055772 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065772 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76461276 0.05051926]]\n",
            "hidden after activation = [[0.70426837 0.85378644 0.51262713]]\n",
            "out value = [[3.02522162e-05]]\n",
            "loss_plus = 9.151965867385483e-10\n",
            "grad = -6.988993962456185e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055779\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486242 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949624 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76461276 0.05051926]]\n",
            "hidden after activation = [[0.70426837 0.85378644 0.51262713]]\n",
            "out value = [[4.5191553e-05]]\n",
            "loss_plus = 2.042276463081753e-09\n",
            "grad = 4.281804800975859e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948624\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279073 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289075 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76461276 0.05051926]]\n",
            "hidden after activation = [[0.70426837 0.85378644 0.51262713]]\n",
            "out value = [[1.1095406e-05]]\n",
            "loss_plus = 1.2310803410466553e-10\n",
            "grad = -1.4909879488795013e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727909\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398909 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979086 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770713 1.76461276 0.05051926]]\n",
            "hidden after activation = [[0.70426837 0.85378644 0.51262713]]\n",
            "out value = [[5.98407805e-05]]\n",
            "loss_plus = 3.5809190138691324e-09\n",
            "grad = 1.9668230308849654e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989105\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.51262722]]\n",
            "out value = [[-4.01636794e-05]]\n",
            "loss_original = 1.6131211433264661e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780718 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70428921 0.85378644 0.51262722]]\n",
            "out value = [[-3.74440988e-05]]\n",
            "loss_plus = 1.4020605378141768e-09\n",
            "grad = -2.110606055122893e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821322 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883132 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76471281 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85379892 0.51262722]]\n",
            "out value = [[-3.64833766e-05]]\n",
            "loss_plus = 1.3310367711351392e-09\n",
            "grad = -2.820843721913269e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821325\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017828 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027826 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.0506196 ]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.5126522 ]]\n",
            "out value = [[-2.08588032e-05]]\n",
            "loss_plus = 4.3508966964027846e-10\n",
            "grad = -1.1780314736861877e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501784\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923815 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933815 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780716 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70428921 0.85378644 0.51262722]]\n",
            "out value = [[-3.7444504e-05]]\n",
            "loss_plus = 1.4020908806960996e-09\n",
            "grad = -2.1103026263036646e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923816\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76471284 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85379893 0.51262722]]\n",
            "out value = [[-3.64822797e-05]]\n",
            "loss_plus = 1.330956733517804e-09\n",
            "grad = -2.8216440980866213e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501774 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502774 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.0506196 ]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.5126522 ]]\n",
            "out value = [[-2.08588032e-05]]\n",
            "loss_plus = 4.3508966964027846e-10\n",
            "grad = -1.1780314736861877e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017752\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075626 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065626 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780716 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70428921 0.85378644 0.51262722]]\n",
            "out value = [[-3.7444504e-05]]\n",
            "loss_plus = 1.4020908806960996e-09\n",
            "grad = -2.1103026263036646e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075624\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821297 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831296 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76471281 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85379892 0.51262722]]\n",
            "out value = [[-3.64833766e-05]]\n",
            "loss_plus = 1.3310367711351392e-09\n",
            "grad = -2.820843721913269e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.488213\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983606 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973605 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.05061963]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.51265221]]\n",
            "out value = [[-2.08530491e-05]]\n",
            "loss_plus = 4.348496573800759e-10\n",
            "grad = -1.1782714859463901e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983594\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055779 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065779 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.51262722]]\n",
            "out value = [[3.0264351e-05]]\n",
            "loss_plus = 9.159309419053424e-10\n",
            "grad = -6.9719020142112365e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055786\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948624 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496238 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.51262722]]\n",
            "out value = [[4.52036878e-05]]\n",
            "loss_plus = 2.0433733864570102e-09\n",
            "grad = 4.3025224313054406e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486236\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727909 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728909 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.51262722]]\n",
            "out value = [[1.11075489e-05]]\n",
            "loss_plus = 1.2337764324394816e-10\n",
            "grad = -1.489743500082518e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.772791\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989105 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979104 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770716 1.76461282 0.05051962]]\n",
            "hidden after activation = [[0.70426838 0.85378644 0.51262722]]\n",
            "out value = [[5.98529145e-05]]\n",
            "loss_plus = 3.5823713775402244e-09\n",
            "grad = 1.969250234213758e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989123\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.51262731]]\n",
            "out value = [[-4.01821003e-05]]\n",
            "loss_original = 1.6146011875966422e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780722 1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70428922 0.85378645 0.51262731]]\n",
            "out value = [[-3.74625183e-05]]\n",
            "loss_plus = 1.4034402744790499e-09\n",
            "grad = -2.111609131175923e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821325 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831323 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76471287 0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85379893 0.51262731]]\n",
            "out value = [[-3.65017981e-05]]\n",
            "loss_plus = 1.332381264662632e-09\n",
            "grad = -2.822199229340102e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821328\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501784 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027838 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05061996]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.51265229]]\n",
            "out value = [[-2.08772213e-05]]\n",
            "loss_plus = 4.358583691701285e-10\n",
            "grad = -1.1787428184265136e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017852\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923816 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933816 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678072  1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70428922 0.85378645 0.51262731]]\n",
            "out value = [[-3.74629234e-05]]\n",
            "loss_plus = 1.4034706322954173e-09\n",
            "grad = -2.1113055530122482e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923818\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.7647129  0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85379894 0.51262731]]\n",
            "out value = [[-3.65007012e-05]]\n",
            "loss_plus = 1.332301186639599e-09\n",
            "grad = -2.8230000095704316e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017752 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502775 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05061996]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.51265229]]\n",
            "out value = [[-2.08772213e-05]]\n",
            "loss_plus = 4.358583691701285e-10\n",
            "grad = -1.1787428184265136e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017764\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075624 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065624 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678072  1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70428922 0.85378645 0.51262731]]\n",
            "out value = [[-3.74629234e-05]]\n",
            "loss_plus = 1.4034706322954173e-09\n",
            "grad = -2.1113055530122482e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075622\n",
            "\n",
            "temp_weights[1][(1,)] = 0.488213 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.488313 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76471287 0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85379893 0.51262731]]\n",
            "out value = [[-3.65017981e-05]]\n",
            "loss_plus = 1.332381264662632e-09\n",
            "grad = -2.822199229340102e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821303\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983594 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497359 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05061999]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.5126523 ]]\n",
            "out value = [[-2.08714672e-05]]\n",
            "loss_plus = 4.3561814491964587e-10\n",
            "grad = -1.1789830426769962e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498358\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055786 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065787 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.51262731]]\n",
            "out value = [[3.02459308e-05]]\n",
            "loss_plus = 9.14816332975812e-10\n",
            "grad = -6.997848546208301e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055794\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486236 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496235 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.51262731]]\n",
            "out value = [[4.51852676e-05]]\n",
            "loss_plus = 2.0417084047727493e-09\n",
            "grad = 4.271072171761071e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486233\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.772791 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289104 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.51262731]]\n",
            "out value = [[1.10891369e-05]]\n",
            "loss_plus = 1.2296895792956412e-10\n",
            "grad = -1.491632229667078e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727912\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989123 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397912 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677072  1.76461288 0.05051997]]\n",
            "hidden after activation = [[0.70426839 0.85378645 0.51262731]]\n",
            "out value = [[5.98344936e-05]]\n",
            "loss_plus = 3.5801666237476608e-09\n",
            "grad = 1.9655654361510182e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398914\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.5126274 ]]\n",
            "out value = [[-4.01699663e-05]]\n",
            "loss_original = 1.6136261906760048e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780725 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.70428923 0.85378646 0.5126274 ]]\n",
            "out value = [[-3.74503827e-05]]\n",
            "loss_plus = 1.4025311635598209e-09\n",
            "grad = -2.110950271161839e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821328 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831326 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76471293 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85379894 0.5126274 ]]\n",
            "out value = [[-3.64896646e-05]]\n",
            "loss_plus = 1.3314956202394706e-09\n",
            "grad = -2.821305704365342e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882133\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017852 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502785 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05062032]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.51265238]]\n",
            "out value = [[-2.08650829e-05]]\n",
            "loss_plus = 4.3535168630027985e-10\n",
            "grad = -1.1782745043757249e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017864\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923818 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933818 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780724 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.70428923 0.85378646 0.5126274 ]]\n",
            "out value = [[-3.74507879e-05]]\n",
            "loss_plus = 1.402561511567107e-09\n",
            "grad = -2.110646791088978e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923819\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76471296 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85379894 0.5126274 ]]\n",
            "out value = [[-3.64885676e-05]]\n",
            "loss_plus = 1.3314155688517152e-09\n",
            "grad = -2.8221062182428964e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017764 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027763 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05062032]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.51265238]]\n",
            "out value = [[-2.08650829e-05]]\n",
            "loss_plus = 4.3535168630027985e-10\n",
            "grad = -1.1782745043757249e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017776\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075622 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065622 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780724 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.70428923 0.85378646 0.5126274 ]]\n",
            "out value = [[-3.74507879e-05]]\n",
            "loss_plus = 1.402561511567107e-09\n",
            "grad = -2.110646791088978e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110756196\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821303 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831302 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76471293 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85379894 0.5126274 ]]\n",
            "out value = [[-3.64896646e-05]]\n",
            "loss_plus = 1.3314956202394706e-09\n",
            "grad = -2.821305704365342e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821306\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498358 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497358 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05062035]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.51265239]]\n",
            "out value = [[-2.08593289e-05]]\n",
            "loss_plus = 4.3511160168373126e-10\n",
            "grad = -1.1785145889922733e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498357\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055794 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065794 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.5126274 ]]\n",
            "out value = [[3.02580657e-05]]\n",
            "loss_plus = 9.155505391399679e-10\n",
            "grad = -6.9807565153603685e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055801\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486233 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496232 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.5126274 ]]\n",
            "out value = [[4.51974024e-05]]\n",
            "loss_plus = 2.042805180892385e-09\n",
            "grad = 4.291789902163803e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948623\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727912 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728912 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.5126274 ]]\n",
            "out value = [[1.11012799e-05]]\n",
            "loss_plus = 1.2323841611831854e-10\n",
            "grad = -1.4903877745576862e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727914\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398914 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397914 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770724 1.76461294 0.05052033]]\n",
            "hidden after activation = [[0.7042684  0.85378646 0.5126274 ]]\n",
            "out value = [[5.98466277e-05]]\n",
            "loss_plus = 3.5816188418373e-09\n",
            "grad = 1.9679926511612954e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398916\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262749]]\n",
            "out value = [[-4.01578322e-05]]\n",
            "loss_original = 1.6126514856493021e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780729 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70428924 0.85378647 0.51262749]]\n",
            "out value = [[-3.74382471e-05]]\n",
            "loss_plus = 1.401622344790685e-09\n",
            "grad = -2.110291408586171e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882133 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883133 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.76471299 0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85379895 0.51262749]]\n",
            "out value = [[-3.6477531e-05]]\n",
            "loss_plus = 1.3306102679208275e-09\n",
            "grad = -2.820412177284746e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821334\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017864 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027862 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.05062068]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51265247]]\n",
            "out value = [[-2.08529446e-05]]\n",
            "loss_plus = 4.3484529678545046e-10\n",
            "grad = -1.1778061888638516e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017875\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923819 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933819 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780728 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70428923 0.85378647 0.51262749]]\n",
            "out value = [[-3.74386523e-05]]\n",
            "loss_plus = 1.4016526829722216e-09\n",
            "grad = -2.109988026770805e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.1892382\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.76471302 0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85379895 0.51262749]]\n",
            "out value = [[-3.64764341e-05]]\n",
            "loss_plus = 1.3305302431684094e-09\n",
            "grad = -2.821212424808927e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017776 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027775 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.05062068]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51265247]]\n",
            "out value = [[-2.08529446e-05]]\n",
            "loss_plus = 4.3484529678545046e-10\n",
            "grad = -1.1778061888638516e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017788\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110756196 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110656194 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780728 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70428923 0.85378647 0.51262749]]\n",
            "out value = [[-3.74386523e-05]]\n",
            "loss_plus = 1.4016526829722216e-09\n",
            "grad = -2.109988026770805e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110756174\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821306 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831305 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.76471299 0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85379895 0.51262749]]\n",
            "out value = [[-3.6477531e-05]]\n",
            "loss_plus = 1.3306102679208275e-09\n",
            "grad = -2.820412177284746e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882131\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498357 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497357 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.0506207 ]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51265247]]\n",
            "out value = [[-2.08471905e-05]]\n",
            "loss_plus = 4.34605351803266e-10\n",
            "grad = -1.1780461338460361e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498356\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055801 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065802 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262749]]\n",
            "out value = [[3.02702006e-05]]\n",
            "loss_plus = 9.162850417484291e-10\n",
            "grad = -6.96366443900873e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055809\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948623 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949623 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262749]]\n",
            "out value = [[4.52095372e-05]]\n",
            "loss_plus = 2.0439022544201664e-09\n",
            "grad = 4.312507687708642e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486227\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727914 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728914 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262749]]\n",
            "out value = [[1.1113423e-05]]\n",
            "loss_plus = 1.2350816992503457e-10\n",
            "grad = -1.4891433157242676e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727915\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398916 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397916 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770727 1.764613   0.05052069]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262749]]\n",
            "out value = [[5.98587617e-05]]\n",
            "loss_plus = 3.5830713582390284e-09\n",
            "grad = 1.9704198725897263e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989177\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262758]]\n",
            "out value = [[-4.0176253e-05]]\n",
            "loss_original = 1.6141313085109797e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780733 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70428924 0.85378647 0.51262758]]\n",
            "out value = [[-3.74566664e-05]]\n",
            "loss_plus = 1.4030018603029742e-09\n",
            "grad = -2.1112944820800553e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821334 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831332 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76471305 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85379895 0.51262758]]\n",
            "out value = [[-3.64959524e-05]]\n",
            "loss_plus = 1.3319545406564632e-09\n",
            "grad = -2.8217676785451645e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821337\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017875 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027874 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05062103]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51265256]]\n",
            "out value = [[-2.08713626e-05]]\n",
            "loss_plus = 4.3561377739172545e-10\n",
            "grad = -1.1785175311192543e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017887\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.1892382 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.1893382 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780731 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70428924 0.85378647 0.51262758]]\n",
            "out value = [[-3.74570716e-05]]\n",
            "loss_plus = 1.4030322134438658e-09\n",
            "grad = -2.1109909506711396e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923822\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76471308 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85379896 0.51262758]]\n",
            "out value = [[-3.64948555e-05]]\n",
            "loss_plus = 1.331874475490426e-09\n",
            "grad = -2.8225683302055376e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017788 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027786 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05062103]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51265256]]\n",
            "out value = [[-2.08713626e-05]]\n",
            "loss_plus = 4.3561377739172545e-10\n",
            "grad = -1.1785175311192543e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.450178\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110756174 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065617 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780731 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70428924 0.85378647 0.51262758]]\n",
            "out value = [[-3.74570716e-05]]\n",
            "loss_plus = 1.4030322134438658e-09\n",
            "grad = -2.1109909506711396e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075615\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882131 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831308 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76471305 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85379895 0.51262758]]\n",
            "out value = [[-3.64959524e-05]]\n",
            "loss_plus = 1.3319545406564632e-09\n",
            "grad = -2.8217676785451645e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821312\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498356 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973557 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05062106]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51265256]]\n",
            "out value = [[-2.08656086e-05]]\n",
            "loss_plus = 4.3537362042463494e-10\n",
            "grad = -1.1787576880863446e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983547\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055809 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065809 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262758]]\n",
            "out value = [[3.02517805e-05]]\n",
            "loss_plus = 9.151702218202127e-10\n",
            "grad = -6.98961086690767e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055816\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486227 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496226 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262758]]\n",
            "out value = [[4.51911171e-05]]\n",
            "loss_plus = 2.0422370639628957e-09\n",
            "grad = 4.2810575545191596e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486224\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727915 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728915 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262758]]\n",
            "out value = [[1.1095011e-05]]\n",
            "loss_plus = 1.2309926995596574e-10\n",
            "grad = -1.4910320385550138e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727917\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989177 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979175 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770731 1.76461306 0.05052105]]\n",
            "hidden after activation = [[0.70426841 0.85378647 0.51262758]]\n",
            "out value = [[5.98403409e-05]]\n",
            "loss_plus = 3.5808663979396316e-09\n",
            "grad = 1.9667350894286517e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989195\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51262767]]\n",
            "out value = [[-4.01641189e-05]]\n",
            "loss_original = 1.6131564462159712e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780737 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70428925 0.85378648 0.51262767]]\n",
            "out value = [[-3.74445308e-05]]\n",
            "loss_plus = 1.4020928846381054e-09\n",
            "grad = -2.1106356157786586e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821337 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831335 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76471311 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85379896 0.51262767]]\n",
            "out value = [[-3.64838188e-05]]\n",
            "loss_plus = 1.3310690314812123e-09\n",
            "grad = -2.820874147347589e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882134\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017887 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027886 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.05062139]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51265265]]\n",
            "out value = [[-2.08592242e-05]]\n",
            "loss_plus = 4.3510723298589467e-10\n",
            "grad = -1.1780492132300766e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.250179\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923822 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933822 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780735 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70428925 0.85378648 0.51262767]]\n",
            "out value = [[-3.74449359e-05]]\n",
            "loss_plus = 1.4021232279615023e-09\n",
            "grad = -2.110332182544689e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923824\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76471314 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85379897 0.51262767]]\n",
            "out value = [[-3.64827218e-05]]\n",
            "loss_plus = 1.330988992950638e-09\n",
            "grad = -2.8216745326533317e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.450178 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027798 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.05062139]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51265265]]\n",
            "out value = [[-2.08592242e-05]]\n",
            "loss_plus = 4.3510723298589467e-10\n",
            "grad = -1.1780492132300766e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017812\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075615 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065615 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780735 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70428925 0.85378648 0.51262767]]\n",
            "out value = [[-3.74449359e-05]]\n",
            "loss_plus = 1.4021232279615023e-09\n",
            "grad = -2.110332182544689e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075613\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821312 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883131 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76471311 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85379896 0.51262767]]\n",
            "out value = [[-3.64838188e-05]]\n",
            "loss_plus = 1.3310690314812123e-09\n",
            "grad = -2.820874147347589e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821315\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983547 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973545 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.05062142]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51265265]]\n",
            "out value = [[-2.08534701e-05]]\n",
            "loss_plus = 4.3486721565387337e-10\n",
            "grad = -1.1782892305620978e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983535\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055816 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065816 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51262767]]\n",
            "out value = [[3.02639154e-05]]\n",
            "loss_plus = 9.159045754295842e-10\n",
            "grad = -6.97251870786387e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055824\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486224 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496223 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51262767]]\n",
            "out value = [[4.5203252e-05]]\n",
            "loss_plus = 2.0433339902285678e-09\n",
            "grad = 4.3017754401259656e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948622\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727917 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728917 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51262767]]\n",
            "out value = [[1.11071541e-05]]\n",
            "loss_plus = 1.2336887281324547e-10\n",
            "grad = -1.4897875734027256e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727918\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989195 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397919 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770735 1.76461312 0.0505214 ]]\n",
            "hidden after activation = [[0.70426842 0.85378648 0.51262767]]\n",
            "out value = [[5.9852475e-05]]\n",
            "loss_plus = 3.5823187687767465e-09\n",
            "grad = 1.969162322560775e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398921\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51262775]]\n",
            "out value = [[-4.01825397e-05]]\n",
            "loss_original = 1.614636496845215e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678074  1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70428926 0.85378649 0.51262775]]\n",
            "out value = [[-3.74629501e-05]]\n",
            "loss_plus = 1.403472628039623e-09\n",
            "grad = -2.111638688055921e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882134 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831338 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76471317 0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85379897 0.51262775]]\n",
            "out value = [[-3.65022401e-05]]\n",
            "loss_plus = 1.3324135323739996e-09\n",
            "grad = -2.822229644712154e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821343\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.250179 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027898 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05062175]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51265274]]\n",
            "out value = [[-2.08776422e-05]]\n",
            "loss_plus = 4.358759429198795e-10\n",
            "grad = -1.1787605539253354e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501791\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923824 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933824 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780739 1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70428926 0.85378649 0.51262775]]\n",
            "out value = [[-3.74633552e-05]]\n",
            "loss_plus = 1.4035029862974104e-09\n",
            "grad = -2.111335105478047e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923825\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.7647132  0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85379897 0.51262775]]\n",
            "out value = [[-3.65011432e-05]]\n",
            "loss_plus = 1.3323334534299193e-09\n",
            "grad = -2.823030434152958e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017812 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502781 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05062175]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51265274]]\n",
            "out value = [[-2.08776422e-05]]\n",
            "loss_plus = 4.358759429198795e-10\n",
            "grad = -1.1787605539253354e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017824\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075613 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065613 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780739 1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70428926 0.85378649 0.51262775]]\n",
            "out value = [[-3.74633552e-05]]\n",
            "loss_plus = 1.4035029862974104e-09\n",
            "grad = -2.111335105478047e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075611\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821315 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831314 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76471317 0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85379897 0.51262775]]\n",
            "out value = [[-3.65022401e-05]]\n",
            "loss_plus = 1.3324135323739996e-09\n",
            "grad = -2.822229644712154e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821318\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983535 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973533 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05062178]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51265274]]\n",
            "out value = [[-2.08718881e-05]]\n",
            "loss_plus = 4.3563571359414926e-10\n",
            "grad = -1.1790007832510657e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498352\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055824 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065824 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51262775]]\n",
            "out value = [[3.02454954e-05]]\n",
            "loss_plus = 9.147899899554974e-10\n",
            "grad = -6.998465068897176e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055831\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948622 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949622 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51262775]]\n",
            "out value = [[4.51848319e-05]]\n",
            "loss_plus = 2.0416690356645263e-09\n",
            "grad = 4.270325388193112e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486218\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727918 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728918 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51262775]]\n",
            "out value = [[1.10887423e-05]]\n",
            "loss_plus = 1.229602047504229e-10\n",
            "grad = -1.491676292094792e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.772792\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398921 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397921 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770739 1.76461318 0.05052176]]\n",
            "hidden after activation = [[0.70426843 0.85378649 0.51262775]]\n",
            "out value = [[5.98340542e-05]]\n",
            "loss_plus = 3.5801140458166267e-09\n",
            "grad = 1.9654775489714113e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398923\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262784]]\n",
            "out value = [[-4.01704055e-05]]\n",
            "loss_original = 1.6136614772830105e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780744 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70428927 0.8537865  0.51262784]]\n",
            "out value = [[-3.74508143e-05]]\n",
            "loss_plus = 1.402563495471819e-09\n",
            "grad = -2.1109798181119147e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821343 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883134 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76471323 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.85379898 0.51262784]]\n",
            "out value = [[-3.64901064e-05]]\n",
            "loss_plus = 1.3315278663351505e-09\n",
            "grad = -2.8213361094785995e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821346\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501791 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502791 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05062211]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51265282]]\n",
            "out value = [[-2.08655037e-05]]\n",
            "loss_plus = 4.3536924361488815e-10\n",
            "grad = -1.1782922336681223e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017923\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923825 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933825 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780743 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70428926 0.8537865  0.51262784]]\n",
            "out value = [[-3.74512195e-05]]\n",
            "loss_plus = 1.4025938439203747e-09\n",
            "grad = -2.1106763336263576e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923827\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76471326 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.85379898 0.51262784]]\n",
            "out value = [[-3.64890095e-05]]\n",
            "loss_plus = 1.3314478140428638e-09\n",
            "grad = -2.8221366324014665e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017824 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027822 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05062211]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51265282]]\n",
            "out value = [[-2.08655037e-05]]\n",
            "loss_plus = 4.3536924361488815e-10\n",
            "grad = -1.1782922336681223e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017835\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075611 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110656105 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780743 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70428926 0.8537865  0.51262784]]\n",
            "out value = [[-3.74512195e-05]]\n",
            "loss_plus = 1.4025938439203747e-09\n",
            "grad = -2.1106763336263576e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110756084\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821318 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831317 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76471323 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.85379898 0.51262784]]\n",
            "out value = [[-3.64901064e-05]]\n",
            "loss_plus = 1.3315278663351505e-09\n",
            "grad = -2.8213361094785995e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882132\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498352 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497352 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05062214]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51265283]]\n",
            "out value = [[-2.08597496e-05]]\n",
            "loss_plus = 4.35129153929572e-10\n",
            "grad = -1.1785323233534383e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498351\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055831 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065831 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262784]]\n",
            "out value = [[3.02576304e-05]]\n",
            "loss_plus = 9.155241945736134e-10\n",
            "grad = -6.98137282709397e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055839\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486218 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496217 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262784]]\n",
            "out value = [[4.51969669e-05]]\n",
            "loss_plus = 2.0427658146892767e-09\n",
            "grad = 4.291043374062662e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486215\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.772792 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.772892 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262784]]\n",
            "out value = [[1.11008854e-05]]\n",
            "loss_plus = 1.2322965666431483e-10\n",
            "grad = -1.4904318206186955e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279216\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398923 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397923 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770742 1.76461324 0.05052212]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262784]]\n",
            "out value = [[5.98461884e-05]]\n",
            "loss_plus = 3.581566271090238e-09\n",
            "grad = 1.967904793807227e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398925\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262793]]\n",
            "out value = [[-4.01582712e-05]]\n",
            "loss_original = 1.6126867496219494e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780748 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70428928 0.8537865  0.51262793]]\n",
            "out value = [[-3.74386786e-05]]\n",
            "loss_plus = 1.4016546550696316e-09\n",
            "grad = -2.1103209455231784e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821346 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831344 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.76471329 0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.85379898 0.51262793]]\n",
            "out value = [[-3.64779727e-05]]\n",
            "loss_plus = 1.3306424924323329e-09\n",
            "grad = -2.8204425718961656e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882135\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017923 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027922 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05062246]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51265291]]\n",
            "out value = [[-2.08533651e-05]]\n",
            "loss_plus = 4.348628376674932e-10\n",
            "grad = -1.1778239119544564e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017935\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923827 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933827 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780746 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70428927 0.8537865  0.51262793]]\n",
            "out value = [[-3.74390838e-05]]\n",
            "loss_plus = 1.4016849936922875e-09\n",
            "grad = -2.1100175592966195e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923828\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.76471332 0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.85379899 0.51262793]]\n",
            "out value = [[-3.64768758e-05]]\n",
            "loss_plus = 1.3305624667594894e-09\n",
            "grad = -2.8212428286246005e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017835 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027834 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05062246]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51265291]]\n",
            "out value = [[-2.08533651e-05]]\n",
            "loss_plus = 4.348628376674932e-10\n",
            "grad = -1.1778239119544564e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017847\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110756084 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065608 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780746 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70428927 0.8537865  0.51262793]]\n",
            "out value = [[-3.74390838e-05]]\n",
            "loss_plus = 1.4016849936922875e-09\n",
            "grad = -2.1100175592966195e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075606\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882132 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883132 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.76471329 0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.85379898 0.51262793]]\n",
            "out value = [[-3.64779727e-05]]\n",
            "loss_plus = 1.3306424924323329e-09\n",
            "grad = -2.8204425718961656e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821324\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498351 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497351 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05062249]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51265292]]\n",
            "out value = [[-2.08476111e-05]]\n",
            "loss_plus = 4.34622887618388e-10\n",
            "grad = -1.1780638620035615e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.649835\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055839 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065839 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262793]]\n",
            "out value = [[3.02697654e-05]]\n",
            "loss_plus = 9.162586956432444e-10\n",
            "grad = -6.9642805397870505e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055846\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486215 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496214 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262793]]\n",
            "out value = [[4.52091019e-05]]\n",
            "loss_plus = 2.043862891119343e-09\n",
            "grad = 4.311761414973937e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486212\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279216 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728922 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262793]]\n",
            "out value = [[1.11130286e-05]]\n",
            "loss_plus = 1.2349940420091776e-10\n",
            "grad = -1.4891873454210315e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727923\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398925 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979247 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770746 1.7646133  0.05052248]]\n",
            "hidden after activation = [[0.70426844 0.8537865  0.51262793]]\n",
            "out value = [[5.98583227e-05]]\n",
            "loss_plus = 3.5830187946831464e-09\n",
            "grad = 1.970332045061197e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989266\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.51262802]]\n",
            "out value = [[-4.0176692e-05]]\n",
            "loss_original = 1.6141665788374875e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780751 1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70428928 0.85378651 0.51262802]]\n",
            "out value = [[-3.74570978e-05]]\n",
            "loss_plus = 1.4030341773210758e-09\n",
            "grad = -2.111324015164117e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882135 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831347 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76471335 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.85379899 0.51262802]]\n",
            "out value = [[-3.6496394e-05]]\n",
            "loss_plus = 1.3319867725029329e-09\n",
            "grad = -2.821798063345546e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821352\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017935 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027934 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05062282]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.512653  ]]\n",
            "out value = [[-2.08717831e-05]]\n",
            "loss_plus = 4.3563132866378914e-10\n",
            "grad = -1.1785352501736982e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017947\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923828 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933828 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678075  1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70428928 0.85378651 0.51262802]]\n",
            "out value = [[-3.7457503e-05]]\n",
            "loss_plus = 1.4030645308780814e-09\n",
            "grad = -2.1110204795940607e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.1892383\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76471338 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.853799   0.51262802]]\n",
            "out value = [[-3.6495297e-05]]\n",
            "loss_plus = 1.3319067064329706e-09\n",
            "grad = -2.8225987240451688e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017847 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027846 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05062282]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.512653  ]]\n",
            "out value = [[-2.08717831e-05]]\n",
            "loss_plus = 4.3563132866378914e-10\n",
            "grad = -1.1785352501736982e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501786\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075606 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065606 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678075  1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70428928 0.85378651 0.51262802]]\n",
            "out value = [[-3.7457503e-05]]\n",
            "loss_plus = 1.4030645308780814e-09\n",
            "grad = -2.1110204795940607e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075604\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821324 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831323 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76471335 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.85379899 0.51262802]]\n",
            "out value = [[-3.6496394e-05]]\n",
            "loss_plus = 1.3319867725029329e-09\n",
            "grad = -2.821798063345546e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821327\n",
            "\n",
            "temp_weights[1][(2,)] = -0.649835 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.649735 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05062285]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.51265301]]\n",
            "out value = [[-2.0866029e-05]]\n",
            "loss_plus = 4.3539116662171727e-10\n",
            "grad = -1.1787754122157703e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498349\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055846 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065846 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.51262802]]\n",
            "out value = [[3.02513454e-05]]\n",
            "loss_plus = 9.151438991496251e-10\n",
            "grad = -6.990226796878623e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055854\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486212 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949621 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.51262802]]\n",
            "out value = [[4.51906819e-05]]\n",
            "loss_plus = 2.042197727748098e-09\n",
            "grad = 4.2803114891061036e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948621\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727923 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728923 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.51262802]]\n",
            "out value = [[1.10946168e-05]]\n",
            "loss_plus = 1.2309052146930684e-10\n",
            "grad = -1.4910760573681805e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279246\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989266 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979264 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677075  1.76461336 0.05052283]]\n",
            "hidden after activation = [[0.70426845 0.85378651 0.51262802]]\n",
            "out value = [[5.98399019e-05]]\n",
            "loss_plus = 3.580813865188778e-09\n",
            "grad = 1.9666472863512904e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989284\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.51262811]]\n",
            "out value = [[-4.01645577e-05]]\n",
            "loss_original = 1.6131916939127793e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780755 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70428929 0.85378652 0.51262811]]\n",
            "out value = [[-3.7444962e-05]]\n",
            "loss_plus = 1.4021251800111866e-09\n",
            "grad = -2.110665139015927e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821352 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883135 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76471341 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.853799   0.51262811]]\n",
            "out value = [[-3.64842602e-05]]\n",
            "loss_plus = 1.3311012417481679e-09\n",
            "grad = -2.8209045216461144e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821355\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017947 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027946 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05062318]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.51265309]]\n",
            "out value = [[-2.08596445e-05]]\n",
            "loss_plus = 4.351247678300582e-10\n",
            "grad = -1.1780669260827212e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501796\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.1892383 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.1893383 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780754 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70428929 0.85378652 0.51262811]]\n",
            "out value = [[-3.74453672e-05]]\n",
            "loss_plus = 1.4021555237671844e-09\n",
            "grad = -2.11036170145595e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923831\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76471344 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.853799   0.51262811]]\n",
            "out value = [[-3.64831633e-05]]\n",
            "loss_plus = 1.331021202297772e-09\n",
            "grad = -2.8217049161500723e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501786 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027858 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05062318]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.51265309]]\n",
            "out value = [[-2.08596445e-05]]\n",
            "loss_plus = 4.351247678300582e-10\n",
            "grad = -1.1780669260827212e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501787\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075604 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065604 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780754 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70428929 0.85378652 0.51262811]]\n",
            "out value = [[-3.74453672e-05]]\n",
            "loss_plus = 1.4021555237671844e-09\n",
            "grad = -2.11036170145595e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075602\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821327 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831326 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76471341 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.853799   0.51262811]]\n",
            "out value = [[-3.64842602e-05]]\n",
            "loss_plus = 1.3311012417481679e-09\n",
            "grad = -2.8209045216461144e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882133\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498349 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973485 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05062321]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.5126531 ]]\n",
            "out value = [[-2.08538904e-05]]\n",
            "loss_plus = 4.3488474542953824e-10\n",
            "grad = -1.1783069484832412e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983475\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055854 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065854 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.51262811]]\n",
            "out value = [[3.02634805e-05]]\n",
            "loss_plus = 9.158782512248292e-10\n",
            "grad = -6.973134426879501e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055861\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948621 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496208 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.51262811]]\n",
            "out value = [[4.52028169e-05]]\n",
            "loss_plus = 2.0432946569407883e-09\n",
            "grad = 4.301029630280089e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486206\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279246 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728925 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.51262811]]\n",
            "out value = [[1.110676e-05]]\n",
            "loss_plus = 1.2336011806361542e-10\n",
            "grad = -1.4898315758491638e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727926\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989284 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397928 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770754 1.76461342 0.05052319]]\n",
            "hidden after activation = [[0.70426846 0.85378652 0.51262811]]\n",
            "out value = [[5.98520362e-05]]\n",
            "loss_plus = 3.582266243221732e-09\n",
            "grad = 1.9690745493089525e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.739893\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.5126282 ]]\n",
            "out value = [[-4.01829784e-05]]\n",
            "loss_original = 1.6146717508664635e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780759 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.7042893  0.85378652 0.5126282 ]]\n",
            "out value = [[-3.74633812e-05]]\n",
            "loss_plus = 1.4035049301319632e-09\n",
            "grad = -2.111668207345003e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821355 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831353 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76471347 0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85379901 0.5126282 ]]\n",
            "out value = [[-3.65026814e-05]]\n",
            "loss_plus = 1.332445749956235e-09\n",
            "grad = -2.8222600091022845e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821357\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501796 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027958 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05062354]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.51265318]]\n",
            "out value = [[-2.08780624e-05]]\n",
            "loss_plus = 4.35893488133222e-10\n",
            "grad = -1.1787782627332414e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501797\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923831 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933831 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780757 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.7042893  0.85378652 0.5126282 ]]\n",
            "out value = [[-3.74637864e-05]]\n",
            "loss_plus = 1.403535288830612e-09\n",
            "grad = -2.1113646203585145e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923832\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.7647135  0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85379901 0.5126282 ]]\n",
            "out value = [[-3.65015845e-05]]\n",
            "loss_plus = 1.3323656701088369e-09\n",
            "grad = -2.8230608075762665e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501787 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502787 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05062354]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.51265318]]\n",
            "out value = [[-2.08780624e-05]]\n",
            "loss_plus = 4.35893488133222e-10\n",
            "grad = -1.1787782627332414e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017883\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075602 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110656016 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780757 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.7042893  0.85378652 0.5126282 ]]\n",
            "out value = [[-3.74637864e-05]]\n",
            "loss_plus = 1.403535288830612e-09\n",
            "grad = -2.1113646203585145e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110755995\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882133 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883133 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76471347 0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85379901 0.5126282 ]]\n",
            "out value = [[-3.65026814e-05]]\n",
            "loss_plus = 1.332445749956235e-09\n",
            "grad = -2.8222600091022845e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821333\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983475 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973474 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05062357]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.51265319]]\n",
            "out value = [[-2.08723083e-05]]\n",
            "loss_plus = 4.356532537401972e-10\n",
            "grad = -1.1790184971262662e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983463\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055861 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065861 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.5126282 ]]\n",
            "out value = [[3.02450606e-05]]\n",
            "loss_plus = 9.147636891737597e-10\n",
            "grad = -6.999080616927037e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055868\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486206 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496205 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.5126282 ]]\n",
            "out value = [[4.5184397e-05]]\n",
            "loss_plus = 2.0416297294612266e-09\n",
            "grad = 4.26957978594763e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486203\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727926 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728926 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.5126282 ]]\n",
            "out value = [[1.10883483e-05]]\n",
            "loss_plus = 1.2295146722914537e-10\n",
            "grad = -1.491720283637318e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279276\n",
            "\n",
            "temp_weights[3][(0,)] = -0.739893 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.739793 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770757 1.76461348 0.05052355]]\n",
            "hidden after activation = [[0.70426847 0.85378652 0.5126282 ]]\n",
            "out value = [[5.98336156e-05]]\n",
            "loss_plus = 3.5800615510816365e-09\n",
            "grad = 1.9653898002151727e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398932\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51262829]]\n",
            "out value = [[-4.0170844e-05]]\n",
            "loss_original = 1.6136967086970633e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780763 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.70428931 0.85378653 0.51262829]]\n",
            "out value = [[-3.74512453e-05]]\n",
            "loss_plus = 1.402595775948752e-09\n",
            "grad = -2.111009327483113e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821357 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831356 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76471353 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85379901 0.51262829]]\n",
            "out value = [[-3.64905476e-05]]\n",
            "loss_plus = 1.3315600623425355e-09\n",
            "grad = -2.8213664635452777e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882136\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501797 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502797 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05062389]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51265327]]\n",
            "out value = [[-2.08659237e-05]]\n",
            "loss_plus = 4.353867724096345e-10\n",
            "grad = -1.178309936287429e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017983\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923832 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933833 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780761 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.7042893  0.85378653 0.51262829]]\n",
            "out value = [[-3.74516505e-05]]\n",
            "loss_plus = 1.4026261248213875e-09\n",
            "grad = -2.1107058387567585e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923834\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76471356 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85379902 0.51262829]]\n",
            "out value = [[-3.64894507e-05]]\n",
            "loss_plus = 1.331480009139134e-09\n",
            "grad = -2.822166995579293e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017883 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027882 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05062389]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51265327]]\n",
            "out value = [[-2.08659237e-05]]\n",
            "loss_plus = 4.353867724096345e-10\n",
            "grad = -1.178309936287429e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017895\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110755995 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065599 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780761 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.7042893  0.85378653 0.51262829]]\n",
            "out value = [[-3.74516505e-05]]\n",
            "loss_plus = 1.4026261248213875e-09\n",
            "grad = -2.1107058387567585e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075597\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821333 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831332 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76471353 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85379901 0.51262829]]\n",
            "out value = [[-3.64905476e-05]]\n",
            "loss_plus = 1.3315600623425355e-09\n",
            "grad = -2.8213664635452777e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821336\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983463 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497346 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05062392]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51265328]]\n",
            "out value = [[-2.08601696e-05]]\n",
            "loss_plus = 4.351466776542402e-10\n",
            "grad = -1.178550031042823e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498345\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055868 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065869 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51262829]]\n",
            "out value = [[3.02571957e-05]]\n",
            "loss_plus = 9.154978922489344e-10\n",
            "grad = -6.9819881644812884e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055876\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486203 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496202 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51262829]]\n",
            "out value = [[4.51965321e-05]]\n",
            "loss_plus = 2.0427265113975882e-09\n",
            "grad = 4.290298027005249e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.294862\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279276 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728928 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51262829]]\n",
            "out value = [[1.11004916e-05]]\n",
            "loss_plus = 1.2322091288228105e-10\n",
            "grad = -1.4904757958147821e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279294\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398932 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397932 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770761 1.76461354 0.05052391]]\n",
            "hidden after activation = [[0.70426848 0.85378653 0.51262829]]\n",
            "out value = [[5.98457499e-05]]\n",
            "loss_plus = 3.5815137835291742e-09\n",
            "grad = 1.967817074832111e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398934\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51262838]]\n",
            "out value = [[-4.01587096e-05]]\n",
            "loss_original = 1.6127219584360044e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780766 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70428931 0.85378654 0.51262838]]\n",
            "out value = [[-3.74391094e-05]]\n",
            "loss_plus = 1.401686913930044e-09\n",
            "grad = -2.1103504450596047e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882136 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883136 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.76471359 0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85379902 0.51262838]]\n",
            "out value = [[-3.64784137e-05]]\n",
            "loss_plus = 1.3306746668639654e-09\n",
            "grad = -2.8204729157203897e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821363\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017983 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502798 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05062425]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51265336]]\n",
            "out value = [[-2.0853785e-05]]\n",
            "loss_plus = 4.348803500462202e-10\n",
            "grad = -1.1778416083897842e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25017995\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923834 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933834 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780765 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70428931 0.85378654 0.51262838]]\n",
            "out value = [[-3.74395146e-05]]\n",
            "loss_plus = 1.4017172529932607e-09\n",
            "grad = -2.110047054427436e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923835\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.76471362 0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85379902 0.51262838]]\n",
            "out value = [[-3.64773168e-05]]\n",
            "loss_plus = 1.3305946402803152e-09\n",
            "grad = -2.821273181556891e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017895 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027894 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05062425]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51265336]]\n",
            "out value = [[-2.0853785e-05]]\n",
            "loss_plus = 4.348803500462202e-10\n",
            "grad = -1.1778416083897842e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017907\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075597 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065597 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780765 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70428931 0.85378654 0.51262838]]\n",
            "out value = [[-3.74395146e-05]]\n",
            "loss_plus = 1.4017172529932607e-09\n",
            "grad = -2.110047054427436e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075595\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821336 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831335 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.76471359 0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85379902 0.51262838]]\n",
            "out value = [[-3.64784137e-05]]\n",
            "loss_plus = 1.3306746668639654e-09\n",
            "grad = -2.8204729157203897e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882134\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498345 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497345 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05062428]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51265337]]\n",
            "out value = [[-2.0848031e-05]]\n",
            "loss_plus = 4.346403949381476e-10\n",
            "grad = -1.1780815634978568e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498344\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055876 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065876 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51262838]]\n",
            "out value = [[3.02693309e-05]]\n",
            "loss_plus = 9.162323917895439e-10\n",
            "grad = -6.9648956664646045e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055883\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.294862 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.294962 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51262838]]\n",
            "out value = [[4.52086672e-05]]\n",
            "loss_plus = 2.0438235907464703e-09\n",
            "grad = 4.3110163231046585e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486197\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279294 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289295 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51262838]]\n",
            "out value = [[1.11126349e-05]]\n",
            "loss_plus = 1.234906541604045e-10\n",
            "grad = -1.4892313042755997e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279305\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398934 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979336 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770765 1.7646136  0.05052426]]\n",
            "hidden after activation = [[0.70426848 0.85378654 0.51262838]]\n",
            "out value = [[5.98578843e-05]]\n",
            "loss_plus = 3.5829663143032078e-09\n",
            "grad = 1.9702443558672033e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989356\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51262847]]\n",
            "out value = [[-4.01771302e-05]]\n",
            "loss_original = 1.6142017939529472e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678077  1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70428932 0.85378655 0.51262847]]\n",
            "out value = [[-3.74575285e-05]]\n",
            "loss_plus = 1.4030664428783179e-09\n",
            "grad = -2.111353510746293e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821363 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831362 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76471364 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85379903 0.51262847]]\n",
            "out value = [[-3.64968349e-05]]\n",
            "loss_plus = 1.3320189542357227e-09\n",
            "grad = -2.8218283971722457e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821366\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25017995 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25027993 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05062461]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51265345]]\n",
            "out value = [[-2.08722028e-05]]\n",
            "loss_plus = 4.3564885140221076e-10\n",
            "grad = -1.1785529425507364e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018007\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923835 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933836 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780769 1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70428932 0.85378655 0.51262847]]\n",
            "out value = [[-3.74579337e-05]]\n",
            "loss_plus = 1.4030967968758305e-09\n",
            "grad = -2.111049970771167e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923837\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76471367 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85379903 0.51262847]]\n",
            "out value = [[-3.64957379e-05]]\n",
            "loss_plus = 1.331938887263355e-09\n",
            "grad = -2.8226290668959233e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017907 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027906 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05062461]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51265345]]\n",
            "out value = [[-2.08722028e-05]]\n",
            "loss_plus = 4.3564885140221076e-10\n",
            "grad = -1.1785529425507364e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501792\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075595 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065595 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780769 1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70428932 0.85378655 0.51262847]]\n",
            "out value = [[-3.74579337e-05]]\n",
            "loss_plus = 1.4030967968758305e-09\n",
            "grad = -2.111049970771167e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075593\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882134 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831338 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76471364 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85379903 0.51262847]]\n",
            "out value = [[-3.64968349e-05]]\n",
            "loss_plus = 1.3320189542357227e-09\n",
            "grad = -2.8218283971722457e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821342\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498344 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497344 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05062464]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51265346]]\n",
            "out value = [[-2.08664488e-05]]\n",
            "loss_plus = 4.3540868430237824e-10\n",
            "grad = -1.1787931096505688e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498343\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055883 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065884 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51262847]]\n",
            "out value = [[3.0250911e-05]]\n",
            "loss_plus = 9.151176187048281e-10\n",
            "grad = -6.990841752481191e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055891\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486197 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496196 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51262847]]\n",
            "out value = [[4.51902473e-05]]\n",
            "loss_plus = 2.0421584544656555e-09\n",
            "grad = 4.279566605127083e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486194\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279305 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728931 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51262847]]\n",
            "out value = [[1.10942232e-05]]\n",
            "loss_plus = 1.2308178864551578e-10\n",
            "grad = -1.4911200053074314e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279323\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989356 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979354 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770768 1.76461366 0.05052462]]\n",
            "hidden after activation = [[0.70426849 0.85378655 0.51262847]]\n",
            "out value = [[5.98394637e-05]]\n",
            "loss_plus = 3.580761415628036e-09\n",
            "grad = 1.966559621675089e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989373\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51262856]]\n",
            "out value = [[-4.01649958e-05]]\n",
            "loss_original = 1.6132268864239876e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780774 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.70428933 0.85378655 0.51262856]]\n",
            "out value = [[-3.74453926e-05]]\n",
            "loss_plus = 1.4021574239565735e-09\n",
            "grad = -2.1106946246741403e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821366 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831365 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.7647137  0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85379904 0.51262856]]\n",
            "out value = [[-3.64847009e-05]]\n",
            "loss_plus = 1.3311334019098703e-09\n",
            "grad = -2.8209348451411733e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882137\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018007 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028005 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.05062497]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51265354]]\n",
            "out value = [[-2.08600641e-05]]\n",
            "loss_plus = 4.35142274157129e-10\n",
            "grad = -1.1780846122668584e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018018\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923837 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933837 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780772 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.70428933 0.85378655 0.51262856]]\n",
            "out value = [[-3.74457977e-05]]\n",
            "loss_plus = 1.4021877681446135e-09\n",
            "grad = -2.1103911827937407e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923838\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76471373 0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85379904 0.51262856]]\n",
            "out value = [[-3.6483604e-05]]\n",
            "loss_plus = 1.3310533615573744e-09\n",
            "grad = -2.8217352486661313e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501792 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027918 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.05062497]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51265354]]\n",
            "out value = [[-2.08600641e-05]]\n",
            "loss_plus = 4.35142274157129e-10\n",
            "grad = -1.1780846122668584e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501793\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075593 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110655926 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780772 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.70428933 0.85378655 0.51262856]]\n",
            "out value = [[-3.74457977e-05]]\n",
            "loss_plus = 1.4021877681446135e-09\n",
            "grad = -2.1103911827937407e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110755906\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821342 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883134 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.7647137  0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85379904 0.51262856]]\n",
            "out value = [[-3.64847009e-05]]\n",
            "loss_plus = 1.3311334019098703e-09\n",
            "grad = -2.8209348451411733e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821345\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498343 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973426 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.050625  ]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51265355]]\n",
            "out value = [[-2.085431e-05]]\n",
            "loss_plus = 4.349022466960648e-10\n",
            "grad = -1.1783246397279228e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983416\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055891 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065891 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51262856]]\n",
            "out value = [[3.02630463e-05]]\n",
            "loss_plus = 9.158519692691122e-10\n",
            "grad = -6.973749171548754e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055898\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486194 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496193 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51262856]]\n",
            "out value = [[4.52023825e-05]]\n",
            "loss_plus = 2.043255386571792e-09\n",
            "grad = 4.300285001478043e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948619\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279323 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289325 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51262856]]\n",
            "out value = [[1.11063666e-05]]\n",
            "loss_plus = 1.233513789934219e-10\n",
            "grad = -1.4898755074305658e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279335\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989373 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397937 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770772 1.76461372 0.05052498]]\n",
            "hidden after activation = [[0.7042685  0.85378655 0.51262856]]\n",
            "out value = [[5.98515981e-05]]\n",
            "loss_plus = 3.5822138008600695e-09\n",
            "grad = 1.968986914436082e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398939\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51262865]]\n",
            "out value = [[-4.01834164e-05]]\n",
            "loss_original = 1.6147069496853338e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780778 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70428934 0.85378656 0.51262865]]\n",
            "out value = [[-3.74638116e-05]]\n",
            "loss_plus = 1.4035371807709186e-09\n",
            "grad = -2.111697689144152e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882137 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831368 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76471376 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85379904 0.51262865]]\n",
            "out value = [[-3.6503122e-05]]\n",
            "loss_plus = 1.3324779174237168e-09\n",
            "grad = -2.82229032261617e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821372\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018018 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028017 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05062532]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51265363]]\n",
            "out value = [[-2.08784819e-05]]\n",
            "loss_plus = 4.359110048037758e-10\n",
            "grad = -1.178795944881558e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501803\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923838 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933839 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780776 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70428933 0.85378656 0.51262865]]\n",
            "out value = [[-3.74642168e-05]]\n",
            "loss_plus = 1.403567539893233e-09\n",
            "grad = -2.1113940979210076e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.1892384\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76471379 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85379905 0.51262865]]\n",
            "out value = [[-3.65020251e-05]]\n",
            "loss_plus = 1.3323978366664147e-09\n",
            "grad = -2.8230911301891907e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501793 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502793 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05062532]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51265363]]\n",
            "out value = [[-2.08784819e-05]]\n",
            "loss_plus = 4.359110048037758e-10\n",
            "grad = -1.178795944881558e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017943\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110755906 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110655904 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780776 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70428933 0.85378656 0.51262865]]\n",
            "out value = [[-3.74642168e-05]]\n",
            "loss_plus = 1.403567539893233e-09\n",
            "grad = -2.1113940979210076e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075588\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821345 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831344 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76471376 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85379904 0.51262865]]\n",
            "out value = [[-3.6503122e-05]]\n",
            "loss_plus = 1.3324779174237168e-09\n",
            "grad = -2.82229032261617e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821348\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983416 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973414 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05062535]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51265364]]\n",
            "out value = [[-2.08727278e-05]]\n",
            "loss_plus = 4.356707653560454e-10\n",
            "grad = -1.1790361843292883e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983404\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055898 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065898 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51262865]]\n",
            "out value = [[3.02446265e-05]]\n",
            "loss_plus = 9.147374306153623e-10\n",
            "grad = -6.999695190699715e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055906\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948619 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949619 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51262865]]\n",
            "out value = [[4.51839627e-05]]\n",
            "loss_plus = 2.041590486140979e-09\n",
            "grad = 4.268835364556454e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486188\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279335 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289337 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51262865]]\n",
            "out value = [[1.1087955e-05]]\n",
            "loss_plus = 1.2294274535670966e-10\n",
            "grad = -1.491764204328624e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279353\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398939 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397939 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770776 1.76461378 0.05052534]]\n",
            "hidden after activation = [[0.70426851 0.85378656 0.51262865]]\n",
            "out value = [[5.98331776e-05]]\n",
            "loss_plus = 3.580009139501012e-09\n",
            "grad = 1.965302189815678e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398941\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51262874]]\n",
            "out value = [[-4.01712818e-05]]\n",
            "loss_original = 1.6137318849074228e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780781 1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70428934 0.85378657 0.51262874]]\n",
            "out value = [[-3.74516756e-05]]\n",
            "loss_plus = 1.4026280049721998e-09\n",
            "grad = -2.11103879935223e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821372 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883137 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76471382 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85379905 0.51262874]]\n",
            "out value = [[-3.6490988e-05]]\n",
            "loss_plus = 1.3315922082435894e-09\n",
            "grad = -2.821396766638334e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821375\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501803 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502803 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.05062568]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51265372]]\n",
            "out value = [[-2.08663431e-05]]\n",
            "loss_plus = 4.354042726827751e-10\n",
            "grad = -1.1783276122246475e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018042\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.1892384 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.1893384 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678078  1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70428934 0.85378657 0.51262874]]\n",
            "out value = [[-3.74520808e-05]]\n",
            "loss_plus = 1.4026583542766717e-09\n",
            "grad = -2.1107353063075106e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923841\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76471385 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85379905 0.51262874]]\n",
            "out value = [[-3.64898911e-05]]\n",
            "loss_plus = 1.3315121541224899e-09\n",
            "grad = -2.8221973078493288e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017943 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502794 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.05062568]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51265372]]\n",
            "out value = [[-2.08663431e-05]]\n",
            "loss_plus = 4.354042726827751e-10\n",
            "grad = -1.1783276122246475e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017955\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075588 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065588 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678078  1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70428934 0.85378657 0.51262874]]\n",
            "out value = [[-3.74520808e-05]]\n",
            "loss_plus = 1.4026583542766717e-09\n",
            "grad = -2.1107353063075106e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075586\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821348 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831347 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76471382 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85379905 0.51262874]]\n",
            "out value = [[-3.6490988e-05]]\n",
            "loss_plus = 1.3315922082435894e-09\n",
            "grad = -2.821396766638334e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882135\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983404 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.649734 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.05062571]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51265373]]\n",
            "out value = [[-2.0860589e-05]]\n",
            "loss_plus = 4.351641728791515e-10\n",
            "grad = -1.1785677120282712e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498339\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055906 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065906 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51262874]]\n",
            "out value = [[3.02567618e-05]]\n",
            "loss_plus = 9.154716321775633e-10\n",
            "grad = -6.982602527298595e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055913\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486188 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496187 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51262874]]\n",
            "out value = [[4.5196098e-05]]\n",
            "loss_plus = 2.0426872710255515e-09\n",
            "grad = 4.289553861181287e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486185\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279353 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289355 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51262874]]\n",
            "out value = [[1.11000984e-05]]\n",
            "loss_plus = 1.2321218476565277e-10\n",
            "grad = -1.4905197001417699e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727937\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398941 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397941 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8677078  1.76461384 0.0505257 ]]\n",
            "hidden after activation = [[0.70426851 0.85378657 0.51262874]]\n",
            "out value = [[5.98453121e-05]]\n",
            "loss_plus = 3.581461379165578e-09\n",
            "grad = 1.967729494258155e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398943\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51262883]]\n",
            "out value = [[-4.01591473e-05]]\n",
            "loss_original = 1.6127571120450625e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780785 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70428935 0.85378658 0.51262883]]\n",
            "out value = [[-3.74395395e-05]]\n",
            "loss_plus = 1.4017191213451944e-09\n",
            "grad = -2.1103799069986805e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821375 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831374 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.76471388 0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85379906 0.51262883]]\n",
            "out value = [[-3.6478854e-05]]\n",
            "loss_plus = 1.3307067911976949e-09\n",
            "grad = -2.8205032084736758e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821378\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018042 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502804 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05062604]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51265381]]\n",
            "out value = [[-2.08542042e-05]]\n",
            "loss_plus = 4.348978339245192e-10\n",
            "grad = -1.1778592781205432e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018054\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923841 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933842 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780784 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70428935 0.85378658 0.51262883]]\n",
            "out value = [[-3.74399447e-05]]\n",
            "loss_plus = 1.4017494608401005e-09\n",
            "grad = -2.11007651204962e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923843\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.76471391 0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85379906 0.51262883]]\n",
            "out value = [[-3.64777571e-05]]\n",
            "loss_plus = 1.330626763712857e-09\n",
            "grad = -2.821303483322054e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017955 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027953 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05062604]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51265381]]\n",
            "out value = [[-2.08542042e-05]]\n",
            "loss_plus = 4.348978339245192e-10\n",
            "grad = -1.1778592781205432e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45017967\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075586 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065586 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780784 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70428935 0.85378658 0.51262883]]\n",
            "out value = [[-3.74399447e-05]]\n",
            "loss_plus = 1.4017494608401005e-09\n",
            "grad = -2.11007651204962e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075584\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882135 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883135 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.76471388 0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85379906 0.51262883]]\n",
            "out value = [[-3.6478854e-05]]\n",
            "loss_plus = 1.3307067911976949e-09\n",
            "grad = -2.8205032084736758e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821354\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498339 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497339 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05062607]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51265381]]\n",
            "out value = [[-2.08484502e-05]]\n",
            "loss_plus = 4.3465787376080173e-10\n",
            "grad = -1.1780992382842606e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498338\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055913 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065913 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51262883]]\n",
            "out value = [[3.02688971e-05]]\n",
            "loss_plus = 9.162061302056878e-10\n",
            "grad = -6.965509818393747e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.1305592\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486185 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496184 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51262883]]\n",
            "out value = [[4.52082332e-05]]\n",
            "loss_plus = 2.0437843533097824e-09\n",
            "grad = 4.310272412647199e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486182\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727937 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728937 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51262883]]\n",
            "out value = [[1.11122419e-05]]\n",
            "loss_plus = 1.234819198117306e-10\n",
            "grad = -1.4892751922333319e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727938\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398943 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979425 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770783 1.7646139  0.05052605]]\n",
            "hidden after activation = [[0.70426852 0.85378658 0.51262883]]\n",
            "out value = [[5.98574466e-05]]\n",
            "loss_plus = 3.582913917163849e-09\n",
            "grad = 1.970156805118786e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989445\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.51262892]]\n",
            "out value = [[-4.01775678e-05]]\n",
            "loss_original = 1.6142369538466182e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780789 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70428936 0.85378658 0.51262892]]\n",
            "out value = [[-3.74579585e-05]]\n",
            "loss_plus = 1.403098656956278e-09\n",
            "grad = -2.1113829689034024e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821378 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831377 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76471394 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85379907 0.51262892]]\n",
            "out value = [[-3.6497275e-05]]\n",
            "loss_plus = 1.3320510858611063e-09\n",
            "grad = -2.821858679855119e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882138\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018054 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028053 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.0506264 ]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.5126539 ]]\n",
            "out value = [[-2.08726219e-05]]\n",
            "loss_plus = 4.356663456098822e-10\n",
            "grad = -1.1785706082367359e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018066\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923843 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933843 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780787 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70428936 0.85378658 0.51262892]]\n",
            "out value = [[-3.74583637e-05]]\n",
            "loss_plus = 1.4031290113937386e-09\n",
            "grad = -2.1110794245287962e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923844\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76471397 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85379907 0.51262892]]\n",
            "out value = [[-3.64961781e-05]]\n",
            "loss_plus = 1.331971017971645e-09\n",
            "grad = -2.822659358749731e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45017967 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027965 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.0506264 ]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.5126539 ]]\n",
            "out value = [[-2.08726219e-05]]\n",
            "loss_plus = 4.356663456098822e-10\n",
            "grad = -1.1785706082367359e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501798\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075584 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065584 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780787 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70428936 0.85378658 0.51262892]]\n",
            "out value = [[-3.74583637e-05]]\n",
            "loss_plus = 1.4031290113937386e-09\n",
            "grad = -2.1110794245287962e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110755816\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821354 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831353 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76471394 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85379907 0.51262892]]\n",
            "out value = [[-3.6497275e-05]]\n",
            "loss_plus = 1.3320510858611063e-09\n",
            "grad = -2.821858679855119e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821357\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498338 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497338 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.05062643]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.5126539 ]]\n",
            "out value = [[-2.08668678e-05]]\n",
            "loss_plus = 4.354261734556089e-10\n",
            "grad = -1.1788107803910092e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498337\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.1305592 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065921 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.51262892]]\n",
            "out value = [[3.02504774e-05]]\n",
            "loss_plus = 9.150913805176038e-10\n",
            "grad = -6.9914557332901445e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055928\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486182 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949618 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.51262892]]\n",
            "out value = [[4.51898135e-05]]\n",
            "loss_plus = 2.042119244083662e-09\n",
            "grad = 4.278822902370437e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948618\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727938 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289385 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.51262892]]\n",
            "out value = [[1.10938303e-05]]\n",
            "loss_plus = 1.230730714829587e-10\n",
            "grad = -1.4911638823636593e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.772794\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989445 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979443 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770787 1.76461396 0.05052641]]\n",
            "hidden after activation = [[0.70426853 0.85378658 0.51262892]]\n",
            "out value = [[5.98390261e-05]]\n",
            "loss_plus = 3.580709049268874e-09\n",
            "grad = 1.9664720954222557e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398946\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51262901]]\n",
            "out value = [[-4.01654332e-05]]\n",
            "loss_original = 1.6132620237388588e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780792 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70428937 0.85378659 0.51262901]]\n",
            "out value = [[-3.74458224e-05]]\n",
            "loss_plus = 1.4021896164558502e-09\n",
            "grad = -2.110724072830086e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882138 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883138 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.764714   0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85379907 0.51262901]]\n",
            "out value = [[-3.6485141e-05]]\n",
            "loss_plus = 1.3311655119725908e-09\n",
            "grad = -2.8209651176626806e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821384\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018066 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028065 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05062675]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51265399]]\n",
            "out value = [[-2.0860483e-05]]\n",
            "loss_plus = 4.351597519792608e-10\n",
            "grad = -1.1781022717595979e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018078\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923844 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933845 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780791 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70428937 0.85378659 0.51262901]]\n",
            "out value = [[-3.74462276e-05]]\n",
            "loss_plus = 1.4022199610753739e-09\n",
            "grad = -2.1104206266348497e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923846\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76471403 0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85379908 0.51262901]]\n",
            "out value = [[-3.64840441e-05]]\n",
            "loss_plus = 1.3310854707195145e-09\n",
            "grad = -2.8217655301934436e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501798 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45027977 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05062675]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51265399]]\n",
            "out value = [[-2.0860483e-05]]\n",
            "loss_plus = 4.351597519792608e-10\n",
            "grad = -1.1781022717595979e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501799\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110755816 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110655814 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780791 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70428937 0.85378659 0.51262901]]\n",
            "out value = [[-3.74462276e-05]]\n",
            "loss_plus = 1.4022199610753739e-09\n",
            "grad = -2.1104206266348497e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110755794\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821357 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831356 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.764714   0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85379907 0.51262901]]\n",
            "out value = [[-3.6485141e-05]]\n",
            "loss_plus = 1.3311655119725908e-09\n",
            "grad = -2.8209651176626806e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882136\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498337 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973366 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05062678]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51265399]]\n",
            "out value = [[-2.08547289e-05]]\n",
            "loss_plus = 4.349197194702335e-10\n",
            "grad = -1.1783423042686252e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983356\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055928 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065928 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51262901]]\n",
            "out value = [[3.02626127e-05]]\n",
            "loss_plus = 9.158257295606309e-10\n",
            "grad = -6.97436294178228e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055936\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948618 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496178 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51262901]]\n",
            "out value = [[4.52019488e-05]]\n",
            "loss_plus = 2.043216179129812e-09\n",
            "grad = 4.299541553909532e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486176\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.772794 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.772894 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51262901]]\n",
            "out value = [[1.11059739e-05]]\n",
            "loss_plus = 1.2334265559609967e-10\n",
            "grad = -1.4899193681427591e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727941\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398946 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397946 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770791 1.76461402 0.05052677]]\n",
            "hidden after activation = [[0.70426854 0.85378659 0.51262901]]\n",
            "out value = [[5.98511607e-05]]\n",
            "loss_plus = 3.58216144170323e-09\n",
            "grad = 1.9688994179643712e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398948\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51262909]]\n",
            "out value = [[-4.01838536e-05]]\n",
            "loss_original = 1.61474209327324e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780796 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70428938 0.8537866  0.51262909]]\n",
            "out value = [[-3.74642413e-05]]\n",
            "loss_plus = 1.4035693799214278e-09\n",
            "grad = -2.111727133518122e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821384 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831383 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76471406 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.85379908 0.51262909]]\n",
            "out value = [[-3.65035619e-05]]\n",
            "loss_plus = 1.3325100347665103e-09\n",
            "grad = -2.8223205850672973e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821387\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018078 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028077 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05062711]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51265408]]\n",
            "out value = [[-2.08789007e-05]]\n",
            "loss_plus = 4.359284929437072e-10\n",
            "grad = -1.178813600329533e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501809\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923846 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933846 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780795 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70428937 0.8537866  0.51262909]]\n",
            "out value = [[-3.74646465e-05]]\n",
            "loss_plus = 1.4035997394834864e-09\n",
            "grad = -2.111423537897537e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923847\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76471409 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.85379908 0.51262909]]\n",
            "out value = [[-3.6502465e-05]]\n",
            "loss_plus = 1.3324299531008237e-09\n",
            "grad = -2.8231214017241633e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501799 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502799 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05062711]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51265408]]\n",
            "out value = [[-2.08789007e-05]]\n",
            "loss_plus = 4.359284929437072e-10\n",
            "grad = -1.178813600329533e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018002\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110755794 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065579 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780795 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70428937 0.8537866  0.51262909]]\n",
            "out value = [[-3.74646465e-05]]\n",
            "loss_plus = 1.4035997394834864e-09\n",
            "grad = -2.111423537897537e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075577\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882136 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883136 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76471406 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.85379908 0.51262909]]\n",
            "out value = [[-3.65035619e-05]]\n",
            "loss_plus = 1.3325100347665103e-09\n",
            "grad = -2.8223205850672973e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821363\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983356 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973354 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05062714]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51265408]]\n",
            "out value = [[-2.08731466e-05]]\n",
            "loss_plus = 4.3568824844922193e-10\n",
            "grad = -1.1790538448240182e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983344\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055936 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065936 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51262909]]\n",
            "out value = [[3.02441931e-05]]\n",
            "loss_plus = 9.147112142785034e-10\n",
            "grad = -7.000308789947367e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055943\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486176 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496175 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51262909]]\n",
            "out value = [[4.51835291e-05]]\n",
            "loss_plus = 2.041551305742113e-09\n",
            "grad = 4.268092124688731e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486173\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727941 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.77289414 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51262909]]\n",
            "out value = [[1.10875624e-05]]\n",
            "loss_plus = 1.2293403913886935e-10\n",
            "grad = -1.4918080541343707e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727943\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398948 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397948 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770795 1.76461408 0.05052713]]\n",
            "hidden after activation = [[0.70426855 0.8537866  0.51262909]]\n",
            "out value = [[5.98327403e-05]]\n",
            "loss_plus = 3.5799568111127914e-09\n",
            "grad = 1.9652147178395513e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.739895\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51262918]]\n",
            "out value = [[-4.0171719e-05]]\n",
            "loss_original = 1.6137670059122717e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.867808   1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70428938 0.85378661 0.51262918]]\n",
            "out value = [[-3.74521052e-05]]\n",
            "loss_plus = 1.4026601825320598e-09\n",
            "grad = -2.1110682338021193e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821387 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831386 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76471412 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85379909 0.51262918]]\n",
            "out value = [[-3.64914278e-05]]\n",
            "loss_plus = 1.3316243040283809e-09\n",
            "grad = -2.8214270188389084e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882139\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501809 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502809 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.05062747]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51265416]]\n",
            "out value = [[-2.08667617e-05]]\n",
            "loss_plus = 4.354217444325691e-10\n",
            "grad = -1.1783452614797025e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018102\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923847 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933848 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780798 1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70428938 0.85378661 0.51262918]]\n",
            "out value = [[-3.74525104e-05]]\n",
            "loss_plus = 1.4026905322761255e-09\n",
            "grad = -2.110764736361462e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923849\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76471415 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85379909 0.51262918]]\n",
            "out value = [[-3.64903309e-05]]\n",
            "loss_plus = 1.3315442489992052e-09\n",
            "grad = -2.8222275691306656e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018002 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.05062747]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51265416]]\n",
            "out value = [[-2.08667617e-05]]\n",
            "loss_plus = 4.354217444325691e-10\n",
            "grad = -1.1783452614797025e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018014\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075577 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065577 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780798 1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70428938 0.85378661 0.51262918]]\n",
            "out value = [[-3.74525104e-05]]\n",
            "loss_plus = 1.4026905322761255e-09\n",
            "grad = -2.110764736361462e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075575\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821363 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831362 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76471412 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85379909 0.51262918]]\n",
            "out value = [[-3.64914278e-05]]\n",
            "loss_plus = 1.3316243040283809e-09\n",
            "grad = -2.8214270188389084e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821366\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983344 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497334 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.0506275 ]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51265417]]\n",
            "out value = [[-2.08610076e-05]]\n",
            "loss_plus = 4.3518163957940555e-10\n",
            "grad = -1.1785853663328662e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498333\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055943 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065943 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51262918]]\n",
            "out value = [[3.02563285e-05]]\n",
            "loss_plus = 9.154454143375436e-10\n",
            "grad = -6.983215915747281e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.1305595\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486173 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496172 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51262918]]\n",
            "out value = [[4.51956645e-05]]\n",
            "loss_plus = 2.042648093561328e-09\n",
            "grad = 4.28881087649056e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948617\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727943 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728943 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51262918]]\n",
            "out value = [[1.1099706e-05]]\n",
            "loss_plus = 1.23203472322657e-10\n",
            "grad = -1.4905635335896146e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727945\n",
            "\n",
            "temp_weights[3][(0,)] = -0.739895 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979497 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770798 1.76461414 0.05052748]]\n",
            "hidden after activation = [[0.70426855 0.85378661 0.51262918]]\n",
            "out value = [[5.9844875e-05]]\n",
            "loss_plus = 3.5814090579976314e-09\n",
            "grad = 1.967642052085359e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989516\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51262927]]\n",
            "out value = [[-4.01595843e-05]]\n",
            "loss_original = 1.612792210474058e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780804 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70428939 0.85378661 0.51262927]]\n",
            "out value = [[-3.7439969e-05]]\n",
            "loss_plus = 1.4017512773216104e-09\n",
            "grad = -2.110409331524475e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882139 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883139 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76471418 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.8537991  0.51262927]]\n",
            "out value = [[-3.64792937e-05]]\n",
            "loss_plus = 1.330738865447893e-09\n",
            "grad = -2.8205334502616493e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821393\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018102 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.250281 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05062783]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51265425]]\n",
            "out value = [[-2.08546227e-05]]\n",
            "loss_plus = 4.3491528930065006e-10\n",
            "grad = -1.1778769211734078e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018114\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923849 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933849 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780802 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70428939 0.85378661 0.51262927]]\n",
            "out value = [[-3.74403742e-05]]\n",
            "loss_plus = 1.401781617247647e-09\n",
            "grad = -2.11010593226411e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.1892385\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76471421 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.8537991  0.51262927]]\n",
            "out value = [[-3.64781967e-05]]\n",
            "loss_plus = 1.3306588370471873e-09\n",
            "grad = -2.8213337342687057e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018014 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028013 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05062783]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51265425]]\n",
            "out value = [[-2.08546227e-05]]\n",
            "loss_plus = 4.3491528930065006e-10\n",
            "grad = -1.1778769211734078e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018026\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075575 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065575 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780802 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70428939 0.85378661 0.51262927]]\n",
            "out value = [[-3.74403742e-05]]\n",
            "loss_plus = 1.401781617247647e-09\n",
            "grad = -2.11010593226411e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075573\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821366 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831365 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76471418 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.8537991  0.51262927]]\n",
            "out value = [[-3.64792937e-05]]\n",
            "loss_plus = 1.330738865447893e-09\n",
            "grad = -2.8205334502616493e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882137\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498333 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497333 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05062786]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51265426]]\n",
            "out value = [[-2.08488687e-05]]\n",
            "loss_plus = 4.346753240892396e-10\n",
            "grad = -1.1781168863848183e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498332\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.1305595 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.1306595 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51262927]]\n",
            "out value = [[3.0268464e-05]]\n",
            "loss_plus = 9.16179910876433e-10\n",
            "grad = -6.966122995976249e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055958\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948617 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949617 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51262927]]\n",
            "out value = [[4.52078e-05]]\n",
            "loss_plus = 2.0437451788074774e-09\n",
            "grad = 4.3095296833341945e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486167\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727945 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728945 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51262927]]\n",
            "out value = [[1.11118496e-05]]\n",
            "loss_plus = 1.2347320114832948e-10\n",
            "grad = -1.4893190093257283e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727946\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989516 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979515 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770802 1.76461419 0.05052784]]\n",
            "hidden after activation = [[0.70426856 0.85378661 0.51262927]]\n",
            "out value = [[5.98570096e-05]]\n",
            "loss_plus = 3.582861603223379e-09\n",
            "grad = 1.970069392749321e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989534\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51262936]]\n",
            "out value = [[-4.01780047e-05]]\n",
            "loss_original = 1.6142720585434478e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780807 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.7042894  0.85378662 0.51262936]]\n",
            "out value = [[-3.74583878e-05]]\n",
            "loss_plus = 1.4031308195947574e-09\n",
            "grad = -2.1114123894869035e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821393 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831392 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76471424 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.8537991  0.51262936]]\n",
            "out value = [[-3.64977146e-05]]\n",
            "loss_plus = 1.332083167377257e-09\n",
            "grad = -2.821888911661907e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821396\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018114 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028113 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.05062819]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51265434]]\n",
            "out value = [[-2.08730403e-05]]\n",
            "loss_plus = 4.3568381129433314e-10\n",
            "grad = -1.1785882472491145e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018126\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.1892385 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.1893385 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780806 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.7042894  0.85378662 0.51262936]]\n",
            "out value = [[-3.7458793e-05]]\n",
            "loss_plus = 1.4031611744549729e-09\n",
            "grad = -2.111108840884749e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923852\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76471427 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.85379911 0.51262936]]\n",
            "out value = [[-3.64966176e-05]]\n",
            "loss_plus = 1.3320030985803247e-09\n",
            "grad = -2.8226895996312307e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018026 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028025 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.05062819]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51265434]]\n",
            "out value = [[-2.08730403e-05]]\n",
            "loss_plus = 4.3568381129433314e-10\n",
            "grad = -1.1785882472491145e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018038\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075573 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110655725 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780806 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.7042894  0.85378662 0.51262936]]\n",
            "out value = [[-3.7458793e-05]]\n",
            "loss_plus = 1.4031611744549729e-09\n",
            "grad = -2.111108840884749e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110755704\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882137 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831367 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76471424 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.8537991  0.51262936]]\n",
            "out value = [[-3.64977146e-05]]\n",
            "loss_plus = 1.332083167377257e-09\n",
            "grad = -2.821888911661907e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821372\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498332 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497332 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.05062822]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51265435]]\n",
            "out value = [[-2.08672862e-05]]\n",
            "loss_plus = 4.354436340982031e-10\n",
            "grad = -1.1788284244452446e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498331\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055958 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065958 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51262936]]\n",
            "out value = [[3.02500444e-05]]\n",
            "loss_plus = 9.150651845458497e-10\n",
            "grad = -6.992068739975981e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055965\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486167 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496166 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51262936]]\n",
            "out value = [[4.51893804e-05]]\n",
            "loss_plus = 2.042080096590282e-09\n",
            "grad = 4.278080380468344e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486164\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727946 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728946 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51262936]]\n",
            "out value = [[1.10934381e-05]]\n",
            "loss_plus = 1.2306436998000466e-10\n",
            "grad = -1.4912076885634431e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727948\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989534 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397953 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770806 1.76461425 0.0505282 ]]\n",
            "hidden after activation = [[0.70426857 0.85378662 0.51262936]]\n",
            "out value = [[5.98385893e-05]]\n",
            "loss_plus = 3.5806567660696143e-09\n",
            "grad = 1.9663847075261667e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398955\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51262945]]\n",
            "out value = [[-4.01658699e-05]]\n",
            "loss_original = 1.6132971058644958e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780811 1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.70428941 0.85378663 0.51262945]]\n",
            "out value = [[-3.74462516e-05]]\n",
            "loss_plus = 1.4022217575072322e-09\n",
            "grad = -2.110753483572636e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821396 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831395 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.7647143  0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85379911 0.51262945]]\n",
            "out value = [[-3.64855803e-05]]\n",
            "loss_plus = 1.3311975719426041e-09\n",
            "grad = -2.8209953392189164e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.388214\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018126 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028124 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05062854]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51265443]]\n",
            "out value = [[-2.08609013e-05]]\n",
            "loss_plus = 4.351772012854509e-10\n",
            "grad = -1.1781199045790448e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018138\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923852 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933852 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678081  1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.7042894  0.85378663 0.51262945]]\n",
            "out value = [[-3.74466568e-05]]\n",
            "loss_plus = 1.4022521025493655e-09\n",
            "grad = -2.110450033151303e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923853\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76471433 0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85379911 0.51262945]]\n",
            "out value = [[-3.64844834e-05]]\n",
            "loss_plus = 1.3311175297742639e-09\n",
            "grad = -2.8217957609023193e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018038 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028037 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05062854]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51265443]]\n",
            "out value = [[-2.08609013e-05]]\n",
            "loss_plus = 4.351772012854509e-10\n",
            "grad = -1.1781199045790448e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501805\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110755704 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.1106557 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678081  1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.7042894  0.85378663 0.51262945]]\n",
            "out value = [[-3.74466568e-05]]\n",
            "loss_plus = 1.4022521025493655e-09\n",
            "grad = -2.110450033151303e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075568\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821372 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883137 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.7647143  0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85379911 0.51262945]]\n",
            "out value = [[-3.64855803e-05]]\n",
            "loss_plus = 1.3311975719426041e-09\n",
            "grad = -2.8209953392189164e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821375\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498331 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973307 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05062857]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51265444]]\n",
            "out value = [[-2.08551472e-05]]\n",
            "loss_plus = 4.349371637364138e-10\n",
            "grad = -1.1783599421280819e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983296\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055965 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065965 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51262945]]\n",
            "out value = [[3.02621799e-05]]\n",
            "loss_plus = 9.157995321043052e-10\n",
            "grad = -6.9749757376019055e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055973\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486164 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496163 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51262945]]\n",
            "out value = [[4.52015158e-05]]\n",
            "loss_plus = 2.043177034623085e-09\n",
            "grad = 4.298799287585891e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948616\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727948 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728948 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51262945]]\n",
            "out value = [[1.11055818e-05]]\n",
            "loss_plus = 1.2333394787741667e-10\n",
            "grad = -1.489963157987079e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727949\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398955 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397955 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770809 1.76461431 0.05052856]]\n",
            "hidden after activation = [[0.70426858 0.85378663 0.51262945]]\n",
            "out value = [[5.9850724e-05]]\n",
            "loss_plus = 3.582109165736109e-09\n",
            "grad = 1.9688120598716128e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398957\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51262954]]\n",
            "out value = [[-4.01842902e-05]]\n",
            "loss_original = 1.6147771816462124e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780815 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70428941 0.85378664 0.51262954]]\n",
            "out value = [[-3.74646704e-05]]\n",
            "loss_plus = 1.4036015276149816e-09\n",
            "grad = -2.1117565403123076e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.388214 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831398 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76471436 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85379912 0.51262954]]\n",
            "out value = [[-3.65040012e-05]]\n",
            "loss_plus = 1.3325421019908952e-09\n",
            "grad = -2.822350796553172e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821402\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018138 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028136 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.0506289 ]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51265452]]\n",
            "out value = [[-2.08793188e-05]]\n",
            "loss_plus = 4.35945952546642e-10\n",
            "grad = -1.1788312290995702e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501815\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923853 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933854 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780813 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70428941 0.85378664 0.51262954]]\n",
            "out value = [[-3.74650756e-05]]\n",
            "loss_plus = 1.4036318876079068e-09\n",
            "grad = -2.1114529403830562e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923855\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76471439 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85379912 0.51262954]]\n",
            "out value = [[-3.65029043e-05]]\n",
            "loss_plus = 1.3324620194264481e-09\n",
            "grad = -2.8231516221976424e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501805 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502805 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.0506289 ]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51265452]]\n",
            "out value = [[-2.08793188e-05]]\n",
            "loss_plus = 4.35945952546642e-10\n",
            "grad = -1.1788312290995702e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018062\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075568 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065568 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780813 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70428941 0.85378664 0.51262954]]\n",
            "out value = [[-3.74650756e-05]]\n",
            "loss_plus = 1.4036318876079068e-09\n",
            "grad = -2.1114529403830562e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075566\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821375 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831373 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76471436 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85379912 0.51262954]]\n",
            "out value = [[-3.65040012e-05]]\n",
            "loss_plus = 1.3325421019908952e-09\n",
            "grad = -2.822350796553172e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821378\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983296 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973295 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.05062893]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51265453]]\n",
            "out value = [[-2.08735647e-05]]\n",
            "loss_plus = 4.357057030087191e-10\n",
            "grad = -1.1790714786374931e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983284\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055973 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065973 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51262954]]\n",
            "out value = [[3.02437604e-05]]\n",
            "loss_plus = 9.146850401680993e-10\n",
            "grad = -7.0009214147811305e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.1305598\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948616 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949616 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51262954]]\n",
            "out value = [[4.51830963e-05]]\n",
            "loss_plus = 2.0415121882226965e-09\n",
            "grad = 4.267350065764841e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486158\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727949 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728949 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51262954]]\n",
            "out value = [[1.10871704e-05]]\n",
            "loss_plus = 1.2292534856660883e-10\n",
            "grad = -1.4918518330796036e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727951\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398957 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397957 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770813 1.76461437 0.05052891]]\n",
            "hidden after activation = [[0.70426858 0.85378664 0.51262954]]\n",
            "out value = [[5.98323037e-05]]\n",
            "loss_plus = 3.5799045658885892e-09\n",
            "grad = 1.965127384242377e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398959\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51262963]]\n",
            "out value = [[-4.01721554e-05]]\n",
            "loss_original = 1.6138020717097954e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780819 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70428942 0.85378664 0.51262963]]\n",
            "out value = [[-3.74525341e-05]]\n",
            "loss_plus = 1.4026923086514969e-09\n",
            "grad = -2.1110976305829853e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821402 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.388314 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76471442 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85379913 0.51262963]]\n",
            "out value = [[-3.64918669e-05]]\n",
            "loss_plus = 1.3316563497193924e-09\n",
            "grad = -2.8214572199040297e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821405\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501815 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028148 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05062926]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51265461]]\n",
            "out value = [[-2.08671797e-05]]\n",
            "loss_plus = 4.354391876665454e-10\n",
            "grad = -1.1783628840432499e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018162\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923855 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933855 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780817 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70428942 0.85378664 0.51262963]]\n",
            "out value = [[-3.74529393e-05]]\n",
            "loss_plus = 1.402722658826282e-09\n",
            "grad = -2.1107941288351347e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923856\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76471445 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85379913 0.51262963]]\n",
            "out value = [[-3.649077e-05]]\n",
            "loss_plus = 1.331576293791762e-09\n",
            "grad = -2.8222577791803332e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018062 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502806 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05062926]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51265461]]\n",
            "out value = [[-2.08671797e-05]]\n",
            "loss_plus = 4.354391876665454e-10\n",
            "grad = -1.1783628840432499e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018074\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075566 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065566 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780817 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70428942 0.85378664 0.51262963]]\n",
            "out value = [[-3.74529393e-05]]\n",
            "loss_plus = 1.402722658826282e-09\n",
            "grad = -2.1107941288351347e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075564\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821378 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831376 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76471442 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85379913 0.51262963]]\n",
            "out value = [[-3.64918669e-05]]\n",
            "loss_plus = 1.3316563497193924e-09\n",
            "grad = -2.8214572199040297e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882138\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983284 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497328 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05062929]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51265462]]\n",
            "out value = [[-2.08614256e-05]]\n",
            "loss_plus = 4.351990777764246e-10\n",
            "grad = -1.1786029939333707e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498327\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.1305598 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.1306598 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51262963]]\n",
            "out value = [[3.02558959e-05]]\n",
            "loss_plus = 9.154192387472319e-10\n",
            "grad = -6.983828329625635e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055988\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486158 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496157 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51262963]]\n",
            "out value = [[4.51952318e-05]]\n",
            "loss_plus = 2.0426089790131548e-09\n",
            "grad = 4.288069073033593e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486156\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727951 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728951 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51262963]]\n",
            "out value = [[1.10993142e-05]]\n",
            "loss_plus = 1.2319477553934124e-10\n",
            "grad = -1.490607296170454e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279526\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398959 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979586 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770817 1.76461443 0.05052927]]\n",
            "hidden after activation = [[0.70426859 0.85378664 0.51262963]]\n",
            "out value = [[5.98444385e-05]]\n",
            "loss_plus = 3.5813568200235193e-09\n",
            "grad = 1.9675547483137236e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989606\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.51262972]]\n",
            "out value = [[-4.01600206e-05]]\n",
            "loss_original = 1.6128272537122595e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780822 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.70428943 0.85378665 0.51262972]]\n",
            "out value = [[-3.74403977e-05]]\n",
            "loss_plus = 1.4017833818741366e-09\n",
            "grad = -2.110438718381229e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821405 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831404 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76471448 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85379913 0.51262972]]\n",
            "out value = [[-3.64797326e-05]]\n",
            "loss_plus = 1.330770889596535e-09\n",
            "grad = -2.8205636411572448e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821408\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018162 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.2502816 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05062962]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.5126547 ]]\n",
            "out value = [[-2.08550405e-05]]\n",
            "loss_plus = 4.34932716168245e-10\n",
            "grad = -1.1778945375440144e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018173\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923856 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933856 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780821 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.70428943 0.85378665 0.51262972]]\n",
            "out value = [[-3.74408029e-05]]\n",
            "loss_plus = 1.4018137222307446e-09\n",
            "grad = -2.110135314815149e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923858\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76471451 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85379914 0.51262972]]\n",
            "out value = [[-3.64786357e-05]]\n",
            "loss_plus = 1.3306908603057803e-09\n",
            "grad = -2.8213639340647913e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018074 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028073 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05062962]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.5126547 ]]\n",
            "out value = [[-2.08550405e-05]]\n",
            "loss_plus = 4.34932716168245e-10\n",
            "grad = -1.1778945375440144e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018086\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075564 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110655636 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780821 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.70428943 0.85378665 0.51262972]]\n",
            "out value = [[-3.74408029e-05]]\n",
            "loss_plus = 1.4018137222307446e-09\n",
            "grad = -2.110135314815149e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110755615\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882138 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883138 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76471448 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85379913 0.51262972]]\n",
            "out value = [[-3.64797326e-05]]\n",
            "loss_plus = 1.330770889596535e-09\n",
            "grad = -2.8205636411572448e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821384\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498327 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497327 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05062965]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.51265471]]\n",
            "out value = [[-2.08492865e-05]]\n",
            "loss_plus = 4.3469274592172415e-10\n",
            "grad = -1.1781345077905352e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498326\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055988 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065988 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.51262972]]\n",
            "out value = [[3.02680315e-05]]\n",
            "loss_plus = 9.161537338067025e-10\n",
            "grad = -6.96673519905557e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13055995\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486156 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496154 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.51262972]]\n",
            "out value = [[4.52073674e-05]]\n",
            "loss_plus = 2.0437060672277193e-09\n",
            "grad = 4.308788135154598e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486153\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279526 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728953 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.51262972]]\n",
            "out value = [[1.1111458e-05]]\n",
            "loss_plus = 1.2346449816363802e-10\n",
            "grad = -1.4893627555486214e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727954\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989606 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979604 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770821 1.76461449 0.05052963]]\n",
            "hidden after activation = [[0.7042686  0.85378665 0.51262972]]\n",
            "out value = [[5.98565733e-05]]\n",
            "loss_plus = 3.582809372493276e-09\n",
            "grad = 1.9699821187810164e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989624\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.51262981]]\n",
            "out value = [[-4.01784408e-05]]\n",
            "loss_original = 1.61430710802378e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780826 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70428944 0.85378666 0.51262981]]\n",
            "out value = [[-3.74588165e-05]]\n",
            "loss_plus = 1.403162930758705e-09\n",
            "grad = -2.111441772650751e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821408 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831407 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76471454 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85379914 0.51262981]]\n",
            "out value = [[-3.64981534e-05]]\n",
            "loss_plus = 1.3321151987580378e-09\n",
            "grad = -2.8219190926574223e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882141\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018173 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028172 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05062997]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.51265479]]\n",
            "out value = [[-2.0873458e-05]]\n",
            "loss_plus = 4.3570124843528803e-10\n",
            "grad = -1.178605859588492e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018185\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923858 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933858 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780825 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70428943 0.85378666 0.51262981]]\n",
            "out value = [[-3.74592216e-05]]\n",
            "loss_plus = 1.4031932860577513e-09\n",
            "grad = -2.111138219660288e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.1892386\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76471457 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85379914 0.51262981]]\n",
            "out value = [[-3.64970564e-05]]\n",
            "loss_plus = 1.332035129063258e-09\n",
            "grad = -2.8227197896052205e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018086 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028085 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05062997]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.51265479]]\n",
            "out value = [[-2.0873458e-05]]\n",
            "loss_plus = 4.3570124843528803e-10\n",
            "grad = -1.178605859588492e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018098\n",
            "\n",
            "temp_weights[1][(0,)] = -0.110755615 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065561 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780825 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70428943 0.85378666 0.51262981]]\n",
            "out value = [[-3.74592216e-05]]\n",
            "loss_plus = 1.4031932860577513e-09\n",
            "grad = -2.111138219660288e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075559\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821384 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831382 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76471454 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85379914 0.51262981]]\n",
            "out value = [[-3.64981534e-05]]\n",
            "loss_plus = 1.3321151987580378e-09\n",
            "grad = -2.8219190926574223e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821387\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498326 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497326 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05063   ]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.5126548 ]]\n",
            "out value = [[-2.08677039e-05]]\n",
            "loss_plus = 4.3546106620525706e-10\n",
            "grad = -1.178846041818523e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498325\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13055995 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13065995 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.51262981]]\n",
            "out value = [[3.02496121e-05]]\n",
            "loss_plus = 9.150390308146363e-10\n",
            "grad = -6.992680772091437e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13056003\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486153 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.2949615 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.51262981]]\n",
            "out value = [[4.51889479e-05]]\n",
            "loss_plus = 2.0420410120138203e-09\n",
            "grad = 4.277339039900402e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948615\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727954 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728954 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.51262981]]\n",
            "out value = [[1.10930467e-05]]\n",
            "loss_plus = 1.2305568413256242e-10\n",
            "grad = -1.4912514238912175e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279556\n",
            "\n",
            "temp_weights[3][(0,)] = -0.73989624 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397962 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770824 1.76461455 0.05052999]]\n",
            "hidden after activation = [[0.70426861 0.85378666 0.51262981]]\n",
            "out value = [[5.98381531e-05]]\n",
            "loss_plus = 3.5806045660550178e-09\n",
            "grad = 1.9662974580312376e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398964\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.5126299 ]]\n",
            "out value = [[-4.01663059e-05]]\n",
            "loss_original = 1.6133321327812486e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.8678083  1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70428945 0.85378667 0.5126299 ]]\n",
            "out value = [[-3.74466801e-05]]\n",
            "loss_plus = 1.4022538471089376e-09\n",
            "grad = -2.1107828567231106e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.3882141 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.3883141 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.7647146  0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85379915 0.5126299 ]]\n",
            "out value = [[-3.6486019e-05]]\n",
            "loss_plus = 1.3312295818099853e-09\n",
            "grad = -2.8210255097126332e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821414\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018185 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028184 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05063033]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51265488]]\n",
            "out value = [[-2.08613188e-05]]\n",
            "loss_plus = 4.351946220739631e-10\n",
            "grad = -1.1781375107072854e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.25018197\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.1892386 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.1893386 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780828 1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70428944 0.85378667 0.5126299 ]]\n",
            "out value = [[-3.74470852e-05]]\n",
            "loss_plus = 1.4022841925897518e-09\n",
            "grad = -2.110479401914968e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923861\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76471463 0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85379915 0.5126299 ]]\n",
            "out value = [[-3.64849221e-05]]\n",
            "loss_plus = 1.3311495387441028e-09\n",
            "grad = -2.8218259403714586e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018098 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028096 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05063033]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51265488]]\n",
            "out value = [[-2.08613188e-05]]\n",
            "loss_plus = 4.351946220739631e-10\n",
            "grad = -1.1781375107072854e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.4501811\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075559 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065559 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780828 1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70428944 0.85378667 0.5126299 ]]\n",
            "out value = [[-3.74470852e-05]]\n",
            "loss_plus = 1.4022841925897518e-09\n",
            "grad = -2.110479401914968e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075557\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821387 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831385 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.7647146  0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85379915 0.5126299 ]]\n",
            "out value = [[-3.6486019e-05]]\n",
            "loss_plus = 1.3312295818099853e-09\n",
            "grad = -2.8210255097126332e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.4882139\n",
            "\n",
            "temp_weights[1][(2,)] = -0.6498325 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.6497325 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05063036]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51265489]]\n",
            "out value = [[-2.08555647e-05]]\n",
            "loss_plus = 4.349545794882386e-10\n",
            "grad = -1.17837755329301e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983237\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13056003 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13066003 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.5126299 ]]\n",
            "out value = [[3.02617478e-05]]\n",
            "loss_plus = 9.15773376891619e-10\n",
            "grad = -6.975587558896295e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.1305601\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.2948615 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496148 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.5126299 ]]\n",
            "out value = [[4.52010835e-05]]\n",
            "loss_plus = 2.0431379530096667e-09\n",
            "grad = 4.298058202284181e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486147\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279556 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728956 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.5126299 ]]\n",
            "out value = [[1.11051905e-05]]\n",
            "loss_plus = 1.2332525583081352e-10\n",
            "grad = -1.4900068769504351e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.7727957\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398964 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397964 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770828 1.76461461 0.05053034]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.5126299 ]]\n",
            "out value = [[5.9850288e-05]]\n",
            "loss_plus = 3.5820569729834716e-09\n",
            "grad = 1.9687248402022228e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398966\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51262999]]\n",
            "out value = [[-4.01847261e-05]]\n",
            "loss_original = 1.6148122148024386e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780833 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70428945 0.85378667 0.51262999]]\n",
            "out value = [[-3.74650987e-05]]\n",
            "loss_plus = 1.4036336238331614e-09\n",
            "grad = -2.111785909692772e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821414 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831413 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76471466 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85379916 0.51262999]]\n",
            "out value = [[-3.65044397e-05]]\n",
            "loss_plus = 1.3325741190869421e-09\n",
            "grad = -2.822380957154965e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.38821417\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.25018197 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028196 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.05063069]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51265497]]\n",
            "out value = [[-2.08797362e-05]]\n",
            "loss_plus = 4.359633836062087e-10\n",
            "grad = -1.17884883119623e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501821\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923861 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933861 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780832 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70428945 0.85378667 0.51262999]]\n",
            "out value = [[-3.74655039e-05]]\n",
            "loss_plus = 1.4036639842563946e-09\n",
            "grad = -2.1114823054604404e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923862\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76471469 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85379916 0.51262999]]\n",
            "out value = [[-3.65033428e-05]]\n",
            "loss_plus = 1.3324940356090437e-09\n",
            "grad = -2.8231817919339496e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.4501811 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.45028108 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.05063069]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51265497]]\n",
            "out value = [[-2.08797362e-05]]\n",
            "loss_plus = 4.359633836062087e-10\n",
            "grad = -1.17884883119623e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018122\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075557 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.11065557 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780832 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70428945 0.85378667 0.51262999]]\n",
            "out value = [[-3.74655039e-05]]\n",
            "loss_plus = 1.4036639842563946e-09\n",
            "grad = -2.1114823054604404e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.11075555\n",
            "\n",
            "temp_weights[1][(1,)] = 0.4882139 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.48831388 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76471466 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85379916 0.51262999]]\n",
            "out value = [[-3.65044397e-05]]\n",
            "loss_plus = 1.3325741190869421e-09\n",
            "grad = -2.822380957154965e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821393\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983237 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973235 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.05063072]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51265498]]\n",
            "out value = [[-2.08739821e-05]]\n",
            "loss_plus = 4.357231290328011e-10\n",
            "grad = -1.1790890857696376e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.64983225\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.1305601 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.1306601 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51262999]]\n",
            "out value = [[3.02433283e-05]]\n",
            "loss_plus = 9.14658908282354e-10\n",
            "grad = -7.001533065200846e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13056017\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486147 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496145 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51262999]]\n",
            "out value = [[4.51826641e-05]]\n",
            "loss_plus = 2.0414731336110314e-09\n",
            "grad = 4.266609188085927e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.29486144\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.7727957 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728957 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51262999]]\n",
            "out value = [[1.10867792e-05]]\n",
            "loss_plus = 1.229166736456869e-10\n",
            "grad = -1.4918955411567516e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279586\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398966 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.7397966 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770832 1.76461467 0.0505307 ]]\n",
            "hidden after activation = [[0.70426862 0.85378667 0.51262999]]\n",
            "out value = [[5.98318678e-05]]\n",
            "loss_plus = 3.579852403826593e-09\n",
            "grad = 1.9650401890241545e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.7398968\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51263008]]\n",
            "out value = [[-4.01725912e-05]]\n",
            "loss_original = 1.613837082316022e-09\n",
            "\n",
            "temp_weights[0][(0, 0)] = 0.7892253 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 0)] = 0.7893253 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780837 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70428946 0.85378668 0.51263008]]\n",
            "out value = [[-3.74529623e-05]]\n",
            "loss_plus = 1.4027243833120988e-09\n",
            "grad = -2.111126990039233e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 0)] = 0.7892253\n",
            "\n",
            "temp_weights[0][(0, 1)] = 0.38821417 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 1)] = 0.38831416 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76471472 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85379916 0.51263008]]\n",
            "out value = [[-3.64923053e-05]]\n",
            "loss_plus = 1.3316883452985962e-09\n",
            "grad = -2.821487370174258e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 1)] = 0.3882142\n",
            "\n",
            "temp_weights[0][(0, 2)] = 0.2501821 before +0.0001 perturbation\n",
            "temp_weights[0][(0, 2)] = 0.25028208 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05063105]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51265506]]\n",
            "out value = [[-2.08675969e-05]]\n",
            "loss_plus = 4.3545660237370247e-10\n",
            "grad = -1.1783804799423195e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(0, 2)] = 0.2501822\n",
            "\n",
            "temp_weights[0][(1, 0)] = 0.18923862 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 0)] = 0.18933862 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780836 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70428946 0.85378668 0.51263008]]\n",
            "out value = [[-3.74533675e-05]]\n",
            "loss_plus = 1.4027547339170442e-09\n",
            "grad = -2.1108234839897783e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 0)] = 0.18923864\n",
            "\n",
            "temp_weights[0][(1, 1)] = 0.88818663 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 1)] = 0.88828665 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76471475 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85379917 0.51263008]]\n",
            "out value = [[-3.64912084e-05]]\n",
            "loss_plus = 1.331608288457825e-09\n",
            "grad = -2.82228793858197e-06\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 1)] = 0.88818663\n",
            "\n",
            "temp_weights[0][(1, 2)] = 0.45018122 before +0.0001 perturbation\n",
            "temp_weights[0][(1, 2)] = 0.4502812 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05063105]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51265506]]\n",
            "out value = [[-2.08675969e-05]]\n",
            "loss_plus = 4.3545660237370247e-10\n",
            "grad = -1.1783804799423195e-05\n",
            "lr = 0.01\n",
            "updated_weights[0][(1, 2)] = 0.45018134\n",
            "\n",
            "temp_weights[1][(0,)] = -0.11075555 before +0.0001 perturbation\n",
            "temp_weights[1][(0,)] = -0.110655546 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86780836 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70428946 0.85378668 0.51263008]]\n",
            "out value = [[-3.74533675e-05]]\n",
            "loss_plus = 1.4027547339170442e-09\n",
            "grad = -2.1108234839897783e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(0,)] = -0.110755526\n",
            "\n",
            "temp_weights[1][(1,)] = 0.48821393 before +0.0001 perturbation\n",
            "temp_weights[1][(1,)] = 0.4883139 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76471472 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85379916 0.51263008]]\n",
            "out value = [[-3.64923053e-05]]\n",
            "loss_plus = 1.3316883452985962e-09\n",
            "grad = -2.821487370174258e-06\n",
            "lr = 0.01\n",
            "updated_weights[1][(1,)] = 0.48821396\n",
            "\n",
            "temp_weights[1][(2,)] = -0.64983225 before +0.0001 perturbation\n",
            "temp_weights[1][(2,)] = -0.64973223 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05063108]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51265507]]\n",
            "out value = [[-2.08618429e-05]]\n",
            "loss_plus = 4.352164874499455e-10\n",
            "grad = -1.1786205948660766e-05\n",
            "lr = 0.01\n",
            "updated_weights[1][(2,)] = -0.6498321\n",
            "\n",
            "temp_weights[2][(0, 0)] = 0.13056017 before +0.0001 perturbation\n",
            "temp_weights[2][(0, 0)] = 0.13066018 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51263008]]\n",
            "out value = [[3.02554641e-05]]\n",
            "loss_plus = 9.153931053981139e-10\n",
            "grad = -6.9844397691790816e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(0, 0)] = 0.13056025\n",
            "\n",
            "temp_weights[2][(1, 0)] = 0.29486144 before +0.0001 perturbation\n",
            "temp_weights[2][(1, 0)] = 0.29496142 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51263008]]\n",
            "out value = [[4.51947998e-05]]\n",
            "loss_plus = 2.0425699273692e-09\n",
            "grad = 4.2873284505317775e-06\n",
            "lr = 0.01\n",
            "updated_weights[2][(1, 0)] = 0.2948614\n",
            "\n",
            "temp_weights[2][(2, 0)] = 0.77279586 before +0.0001 perturbation\n",
            "temp_weights[2][(2, 0)] = 0.7728959 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51263008]]\n",
            "out value = [[1.10989231e-05]]\n",
            "loss_plus = 1.2318609442640222e-10\n",
            "grad = -1.4906509878896197e-05\n",
            "lr = 0.01\n",
            "updated_weights[2][(2, 0)] = 0.77279603\n",
            "\n",
            "temp_weights[3][(0,)] = -0.7398968 before +0.0001 perturbation\n",
            "temp_weights[3][(0,)] = -0.73979676 after +0.0001 perturbation\n",
            "\n",
            "hidden before activation = [[0.86770836 1.76461473 0.05053106]]\n",
            "hidden after activation = [[0.70426863 0.85378668 0.51263008]]\n",
            "out value = [[5.98440028e-05]]\n",
            "loss_plus = 3.5813046652148544e-09\n",
            "grad = 1.967467582898832e-05\n",
            "lr = 0.01\n",
            "updated_weights[3][(0,)] = -0.73989695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss over increasing number of epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:50.265635Z",
          "start_time": "2020-09-24T13:36:50.262366Z"
        },
        "id": "Hyul1G_CDFy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d91656-26f3-44d0-94ad-a3b7730b6050"
      },
      "source": [
        "W"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.7892253 , 0.3882142 , 0.2501822 ],\n",
              "        [0.18923864, 0.88818663, 0.45018134]], dtype=float32),\n",
              " array([-0.11075553,  0.48821396, -0.6498321 ], dtype=float32),\n",
              " array([[0.13056025],\n",
              "        [0.2948614 ],\n",
              "        [0.77279603]], dtype=float32),\n",
              " array([-0.73989695], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:50.269686Z",
          "start_time": "2020-09-24T13:36:50.266775Z"
        },
        "id": "zWGav-f7DIhI"
      },
      "source": [
        "pre_hidden = np.dot(x,W[0]) + W[1]\n",
        "hidden = 1/(1+np.exp(-pre_hidden))\n",
        "out = np.dot(hidden, W[2]) + W[3]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-24T13:36:50.273559Z",
          "start_time": "2020-09-24T13:36:50.271055Z"
        },
        "id": "30Wqe4KADQFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79222f75-b10b-4edd-e326-d4587db69b95"
      },
      "source": [
        "out"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.01604562e-05]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqapuMCwDQiJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}